{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30a7c5c-5ee2-4210-aec8-521c672a54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import plotly.express as px \n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "import seaborn as sns\n",
    "sys.path.insert(1, \"../src/utils/\")\n",
    "from agent import Environment\n",
    "from Q_learning import QLearningTrainer\n",
    "sys.path.insert(1, \"plotly_graph/\")\n",
    "from functions4tuto import rocket_simulation, plot_rocket_altitude, plot_reward_rocket_monoagent\n",
    "JOSN_file = \"rocket_tuto_2a.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ffc6d0",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Input file</span>\n",
    "\n",
    "In the previous tutorial we defined our environment and designed a reward function. The system is a rocket that falling from a starting point and the goal is to reach a target with a minimum speed and maximize fuel.\n",
    "Variable's names, their initial values and boundaries limit are defined into a JSON file (or can be given directly into a dictionary)\n",
    "\n",
    "## <span style=\"color:orange\">Variables</span>\n",
    "\n",
    "Variables can be categorize into 3 classes:\n",
    "* `states_variables` : variable used as coordinate to describe our system\n",
    "* `agent_variables` : variable use as agent. Their values are changed for each iteration\n",
    "* 3th category are other variables. They are not used to describe our environment but they can be usefull to monitor information or to compute intermediate value. \n",
    "  There is no key for this kind of variable. Consider them as variables present into `initial_values` field and that are not `states_variables` and `agent_variables`\n",
    "\n",
    "You can access to the name of state and agent variables, with the attibute `states_variables` and `agent_variables`.\n",
    "\n",
    "    \"states_variables\" : [\"pos_y\", \"acceleration_y\", \"speed_y\"],\n",
    "    \"agent_variables\" : [\"booster\"]\n",
    "\n",
    "## <span style=\"color:orange\">Initial system</span>\n",
    "\n",
    "After to name `states_variables` and `agent_variables`, next step is to define initial state.\n",
    "It will be use as environment coordinates at the beginning of each episode. Initially, it comprises \n",
    "the values of state_variables, followed by agent_variables, and finally other variables that are \n",
    "not used for the system's coordinates.\n",
    "\n",
    "    \"initial_values\" : {\n",
    "      \"pos_y\" : [175.0],\n",
    "      \"speed_x\": [0.0],\n",
    "      \"speed_y\": [0.0],\n",
    "      \"weight_rocket\" : [305],\n",
    "      \"booster\" : [0.0],\n",
    "      \"acceleration_y\": [0.0],\n",
    "      \"m_fuel\" : [300],\n",
    "      \"futur_pos_y\" : [175.0],\n",
    "      \"weight_dry_rocket\" : [5],\n",
    "      \"G\" : [1.62],\n",
    "      \"m_fuel_ini\" : [300.0],\n",
    "      \"pos_y_star\": [0.0],\n",
    "      \"pos_y_ini\" : [175.0],\n",
    "      \"dt\" : [2]\n",
    "      }\n",
    "\n",
    "**NB:** Because we do not modify rocket's angle, we will not show ```pos_x, speed_x and acceleration_x (you can see all variable by calling env.json[\"initial_values\"])```\n",
    "\n",
    "## <span style=\"color:orange\">Limit</span>\n",
    "\n",
    "Q-learning algorithms model events as a Markov process. Therefore, it is necessary to discretize our environment space. \n",
    "We define lower and upper bounds, as well as the number of divisions we want to use to discretize the variable space.\n",
    "\n",
    "\n",
    "    \"limit\" : {\n",
    "      \"pos_x\" : [0.0, 300, 61],\n",
    "      \"pos_y\" : [0.0, 200.0, 81],\n",
    "      \"angle\" : [-0.8, 0.8, 3],\n",
    "      \"speed_y\": [-30.0, 30.0, 13],\n",
    "      \"weight_rocket\" : [0.0, 305, 62],\n",
    "      \"booster\" : [0.0, 2.0, 3],\n",
    "      \"acceleration_y\": [-20.0, 20.0, 21],\n",
    "      \"m_fuel\" : [0.0, 400, 801]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4b678",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Agents's actions</span>\n",
    "    \"n_action\" : {\n",
    "      \"booster\": {\"0\" : 0.0, \"1\" : 1.0, \"2\" : 2.0}\n",
    "    }\n",
    "\n",
    "After defining the variables and their initial values, we proceed to define actions that apply to the agent variables. In this example, we have 1 agent that can take 3 actions:\n",
    "\n",
    "For the booster:\n",
    "  * \"0\": Booster is off.\n",
    "  * \"1\": Booster is turned on to half of its power.\n",
    "  * \"2\": Booster is turned on to its full power.\n",
    "\n",
    "## <span style=\"color:orange\">Actions to take</span>\n",
    "\n",
    "    \"action_to_take\" : {\n",
    "      \"booster\": {\"$booster$\" : \"$action}\n",
    "    }\n",
    "\n",
    "Actions change the agent variables by modifying their values based on the action taken, which are retrieved from the n_action dictionary. You can change default delimiter during the initilisation:\n",
    "\n",
    "`agent = Environment(json_file, delimiter = \"Char_you_want\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba311d",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">System's evolution and reward</span>\n",
    "\n",
    "Last fields are how variables evolve after agents's action and how reward are computed.\n",
    "Only variables present in field inital value are stored. Other variables present are just temporary and are lost after each iteration.\n",
    "Reward values are stored into a dictionnary, the keys are agent variable's name.\n",
    "Timestep value (dt) is 3, to let the system evolve enough without the need to have an high resolution in state variable's space.\n",
    "\n",
    "### <span style=\"color:orange\">Equation variables</span>\n",
    "    \"equations_variables\": {\n",
    "        \"$F$\" : \"600\",\n",
    "        \"$y_0$\" : \"$pos_y$\",\n",
    "        \"$Vy_0$\" : \"$speed_y$\",\n",
    "        \"$m_fuel$\" : \"$m_fuel$ - $booster$ *5 -np.ceil( np.abs($alpha$) ) *5\",\n",
    "        \"$weight_rocket$\" : \"$weight_dry_rocket$ + $m_fuel$\",\n",
    "        \"$acceleration_y$\" : \"($F$/(5+$weight_rocket$) * np.cos($angle$)) * $booster$ - $G$\",\n",
    "        \"$speed_y$\" : \"($F$/(5+$weight_rocket$) * np.cos($angle$)) * $booster$ * $dt$ - $G$ * $dt$ + $Vy_0$\",\n",
    "        \"$pos_x$\": \"(0.5 * $F$/(5+$weight_rocket$) * np.sin($angle$)) * $booster$ * $dt$**2 + $Vx_0$ * $dt$ + $x_0$\",\n",
    "        \"$pos_y$\": \"(0.5 * $F$/(5+$weight_rocket$) * np.cos($angle$)) * $booster$ * $dt$**2 - $G$ * $dt$**2 + $Vy_0$ * $dt$ + $y_0$\",\n",
    "        \"$futur_pos_y$\" : \"$pos_y$ + 3 * $speed_y$\",\n",
    "        \"y_lower_limit\" : \"0\",\n",
    "        \"y_upper_limit\" : \"200\",\n",
    "        \"$upper_boundary$\": \"-np.exp(0) + np.exp(np.min([ np.min(-$futur_pos_y$ + y_upper_limit), 0]))\",\n",
    "        \"$lower_boundary$\": \"-np.exp(0) + np.exp(np.min([ np.min($futur_pos_y$ -y_lower_limit), 0]))\"\n",
    "    },\n",
    "\n",
    "### <span style=\"color:orange\">Reward</span>\n",
    "\n",
    "The reward indicates the immediate benefit or cost associated with the action.\n",
    "The scalar feedback signal that the environment sends to the agent after it takes an action are defined into this dictionnary.\n",
    "\n",
    "    \"equations_rewards\": {\n",
    "      \"$booster$\" : \"2*(-distance_y_reward) + speed_y_reward + 0.5 * ratio_fuel\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Stop episode</span>\n",
    "\n",
    "stop episode when goal is reach. If feature has 1 value, its feature's value must be equal.\n",
    "In other hand, if feature has 2 values ([min_limit, max_limit]), criterion is bounded feature >= min_limit and feature <= max_limit\n",
    "\n",
    "    \"stop_episode\" : {\n",
    "      \"pos_y\" : [0, 5],\n",
    "      \"acceleration_y\" : [-2,2],\n",
    "      \"speed_y\" : [-2,2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae6973",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">A simple scenario</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84614d8e",
   "metadata": {},
   "source": [
    "We want to land our rocket without it crashing. In this scenario, the rocket can take three actions: turn off its booster, or turn it on at half or full power.\n",
    "\n",
    "Letâ€™s model our ideal scenario. We want to activate the booster when the rocket exceeds speed or acceleration limits, and on the other hand, we want to conserve fuel whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d7405-5fcf-45ee-8abf-c1af457b58b9",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Intialize environment</span>\n",
    "\n",
    "Create an environment object with the rules defined previously. The idea is to check the new field can raise a flag to stop simulation when the criteria are reached:\n",
    "\n",
    "* 0 <= pos_y >= 5\n",
    "* -5 <= acceleration_y >= 5\n",
    "\n",
    "We will also control the speed of the rocket and its acceleration to keep as possible those parameters between this range:\n",
    "\n",
    "* -5 >= speed_y <= 5\n",
    "* -10 <= acceleration_y >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed limit\n",
      "turn on engine to increase speed\n",
      "speed limit\n",
      "turn on engine to increase speed\n",
      "speed limit\n",
      "turn on engine to increase speed\n",
      "speed limit\n",
      "turn on engine to increase speed\n",
      "orcket is bellow the ground\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Height",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15,
          18,
          21
         ],
         "y": [
          175,
          160.42,
          131.26,
          96.37245901639344,
          64.75737704918032,
          36.714837454848556,
          12.555185060984357,
          -7.400438294767323
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+0",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15,
          18,
          21
         ],
         "y": [
          175,
          160.42,
          131.26,
          96.37245901639344,
          64.75737704918032,
          36.714837454848556,
          12.555185060984357,
          -7.400438294767323
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Rocket's altitude"
        },
        "xaxis": {
         "title": {
          "text": "Time step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Altitude"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an environment object with the rules defined previously\n",
    "env_ref = Environment(JOSN_file, check_model = False)\n",
    "df_0 = rocket_simulation(env_ref, acceleration_y_constraint = 10, speed_y_limit = 5, timestep = 0)\n",
    "plot_rocket_altitude(df_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f594d",
   "metadata": {},
   "source": [
    "Altitude plot reveals at t = 12, rocket's speed is to high. Indeed, in the next timestep rocket's position is -8.14. If we look to the speed, we can see final speed is bellow -12.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0dd235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_y</th>\n",
       "      <th>speed_y</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>booster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.420000</td>\n",
       "      <td>-4.860000</td>\n",
       "      <td>-1.620000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.260000</td>\n",
       "      <td>-9.720000</td>\n",
       "      <td>-1.620000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.372459</td>\n",
       "      <td>-8.678361</td>\n",
       "      <td>0.347213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.757377</td>\n",
       "      <td>-7.538361</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.714837</td>\n",
       "      <td>-6.296666</td>\n",
       "      <td>0.413898</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.555185</td>\n",
       "      <td>-4.949769</td>\n",
       "      <td>0.448966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-7.400438</td>\n",
       "      <td>-3.493980</td>\n",
       "      <td>0.485263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pos_y   speed_y  acceleration_y  booster\n",
       "0  175.000000  0.000000        0.000000      0.0\n",
       "1  160.420000 -4.860000       -1.620000      0.0\n",
       "2  131.260000 -9.720000       -1.620000      0.0\n",
       "3   96.372459 -8.678361        0.347213      1.0\n",
       "4   64.757377 -7.538361        0.380000      1.0\n",
       "5   36.714837 -6.296666        0.413898      1.0\n",
       "6   12.555185 -4.949769        0.448966      1.0\n",
       "7   -7.400438 -3.493980        0.485263      1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0[[\"pos_y\", \"speed_y\", \"acceleration_y\", \"booster\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54146bb",
   "metadata": {},
   "source": [
    "Speed and final position are not fully filled success criteria. To avoid crash (situation where the speed is too high to be correct at the next timestep), we will use futur position as criterion. Furtur position is compute by using speed and timestep as:\n",
    "\n",
    "$$ futur\\_positiion = pos_y + speed_y * timestep $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4752616",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestep in [3, 5, 10]:\n",
    "    df_0[\"futur_position_dt+{0}\".format(timestep)] = df_0[\"pos_y\"] + df_0[\"speed_y\"] * timestep\n",
    "#plot_rocket_altitude(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "425da7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Height",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          160.42,
          131.26,
          87.51999999999998,
          38.05245901639341,
          -8.142622950819714
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+0",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          160.42,
          131.26,
          87.51999999999998,
          38.05245901639341,
          -8.142622950819714
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+3",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          145.83999999999997,
          102.1,
          43.77999999999997,
          -2.5626229508197156,
          -45.33770491803284
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+5",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          136.11999999999998,
          82.66,
          14.619999999999976,
          -29.639344262295126,
          -70.13442622950825
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+10",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          111.82,
          34.05999999999999,
          -58.28000000000003,
          -97.33114754098366,
          -132.1262295081968
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Rocket's altitude"
        },
        "xaxis": {
         "title": {
          "text": "Time step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Altitude"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rocket_altitude(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "644aa3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Height",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          160.42,
          131.26,
          87.51999999999998,
          38.05245901639341,
          -8.142622950819714
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+0",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          160.42,
          131.26,
          87.51999999999998,
          38.05245901639341,
          -8.142622950819714
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+3",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          145.83999999999997,
          102.1,
          43.77999999999997,
          -2.5626229508197156,
          -45.33770491803284
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+5",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          136.11999999999998,
          82.66,
          14.619999999999976,
          -29.639344262295126,
          -70.13442622950825
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+10",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          111.82,
          34.05999999999999,
          -58.28000000000003,
          -97.33114754098366,
          -132.1262295081968
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Rocket's altitude"
        },
        "xaxis": {
         "title": {
          "text": "Time step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Altitude"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rocket_altitude(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578ff7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Height",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          160.42,
          131.26,
          87.51999999999998,
          38.05245901639341,
          -8.142622950819714
         ]
        },
        {
         "mode": "lines+markers",
         "name": "futur_position_dt+10",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15
         ],
         "y": [
          175,
          111.82,
          34.05999999999999,
          -58.28000000000003,
          -97.33114754098366,
          -132.1262295081968
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Rocket's altitude"
        },
        "xaxis": {
         "title": {
          "text": "Time step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Altitude"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rocket_altitude(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e799b66",
   "metadata": {},
   "source": [
    "Let's examine the rocket's landing, as well as its speed and acceleration throughout the descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d8ce7",
   "metadata": {},
   "source": [
    "Let's see how each global reward and its individual components evolve, without their weighting coefficients. As a reminder, the reward formula for the booster is:\n",
    "\n",
    "$$  -2 * distance\\_y\\_reward + speed\\_y\\_reward + 0.5 * ratio\\_fuel $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6c6882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "distance_y_reward",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15,
          18,
          21
         ],
         "y": [
          1,
          0.9166857142857142,
          0.7500571428571428,
          0.5506997658079625,
          0.37004215456674466,
          0.20979907117056318,
          0.07174391463419633,
          0.04228821882724185
         ]
        },
        {
         "mode": "lines+markers",
         "name": "speed_y_reward",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15,
          18,
          21
         ],
         "y": [
          0,
          0,
          -4.268359890369506,
          -2.9544575190811746,
          -1.7979235858408669,
          -0.8047895085657357,
          0,
          0
         ]
        },
        {
         "mode": "lines+markers",
         "name": "ratio_fuel",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15,
          18,
          21
         ],
         "y": [
          1,
          1,
          1,
          0.9833333333333333,
          0.9666666666666667,
          0.95,
          0.9333333333333333,
          0.9166666666666666
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Sum of rewards",
         "type": "scatter",
         "x": [
          0,
          3,
          6,
          9,
          12,
          15,
          18,
          21
         ],
         "y": [
          -1.5,
          -1.3333714285714284,
          -5.268474176083792,
          -3.5641903840304328,
          -2.054674561641023,
          -0.7493876509068621,
          0.323178837398274,
          0.3737568956788496
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Reward and its components"
        },
        "xaxis": {
         "title": {
          "text": "Time step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_reward_rocket_monoagent(env_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc9cc0",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Reinforcemet learning</span>\n",
    "\n",
    "\n",
    "After load our environment, next step is to create QLearningTrainer objet. It will apply Qlearning algorithm. For each states, the algorithm will apply a score base to the next iteration.\n",
    "\n",
    "The Bellman equation is the value function use in reinforcement learning. \n",
    "\n",
    "$v(s) = (1âˆ’\\alpha) * V(s)+ \\alpha * (R+\\gamma * V(s'))$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $V(s)$ is the estimated value of state $s$ * $s$ is the curent state\n",
    "* $s'$ is the next state.\n",
    "* $R$ is the immediate reward received after transitioning from state $s$ to state\n",
    "* $\\gamma$ is the discount factor, which determines the importance of future rewards.\n",
    "* $\\alpha$ is the learning rate.\n",
    "s.l difference (TD) learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c07191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check order names for states_variables\n",
      "Warning : State variable order are not the  (not a fatal error):\n",
      "state_variables : speed_y, initial_value: speed_y, limit: acceleration_y\n",
      "Warning : State variable order are not the  (not a fatal error):\n",
      "state_variables : weight_rocket, initial_value: weight_rocket, limit: speed_y\n",
      "\n",
      "Check order names for agent_variables\n",
      "Warning : agent variable order are not the same:\n",
      "Warning : agent_variables : booster, initial_value: booster, limit: weight_rocket\n",
      "\n",
      "check limit number of field\n",
      "\n",
      "Check limit boundaries for initial state\n",
      "\n",
      "Solve equations present in equations_variables field\n",
      "\n",
      "Solve equations present in equations_rewards field\n",
      "\n",
      "Everything is good :)\n"
     ]
    }
   ],
   "source": [
    "# Load RL object\n",
    "env = Environment(JOSN_file, check_model = True)\n",
    "RL = QLearningTrainer(env, \n",
    "                      num_episodes = 1000, \n",
    "                      convergence_criterion = 0.5, \n",
    "                      decay_type = \"exponential\",\n",
    "                      decrease_prob_exp = 0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d31355",
   "metadata": {},
   "source": [
    "Different parameters are avaible. For the tutorial, you use default parameters. Before to lunch training. Lets discus about the input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c9872",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Learning rate</span>\n",
    "\n",
    "\n",
    "The learning rate $\\alpha$ in the Bellman equation controls the weight given to the new estimate compared to the existing estimate of the state value. A smaller learning rate means that the new estimate has less influence, and the agent is more conservative in updating its value function. A larger learning rate allows the agent to adjust its estimates more rapidly based on new information\n",
    "\n",
    "### <span style=\"color:orange\">Discount factor ($\\gamma$)</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:orange\">Epsilon parameter</span>\n",
    "\n",
    "Exploration-exploitation is a fundamental trade-off in reinforcement learning, where the agent needs to balance between exploring new actions and exploiting the knowledge it has gained so far.\n",
    "\n",
    "The epsilon-greedy policy is a simple strategy that the agent uses to decide whether to explore a new action (random exploration) or exploit the current best-known action. It helps prevent the agent from getting stuck in suboptimal policies by occasionally trying new actions. The value of epsilon determines the probabilty the agent chooses a random action. A higher epsilon encourages more exploration, while a lower epsilon emphasizes exploitation of the current best-known actions.ent knowledge.\n",
    "\n",
    "The epsilon parameter is decayed over time during training. This means that, as the agent gains more experience, it tends to rely more on exploitation and less on exploration. The idea is that, as the agent learns and becomes more confident in its estimates, it gradually reduces the rate of exploration. \n",
    "\n",
    "Epsilon initailization is made with the argument **exploration_prob**. It is a list with the lowest and the highest probability values. The probability will decrease with a rate given by the argument **decrease_prob_exp**. By default epsilon is modeled with a linear decay but you can change it to a exponential decay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b309bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(RL.get_epsilon(decay_type = 'linear')[0:400], label = \"linear decay\")\n",
    "plt.plot(RL.get_epsilon(decay_type = 'exponential')[0:400], label = \"exponential decay\")\n",
    "plt.title(\"Probability to choose a random action\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"# episode\")\n",
    "plt.ylabel(\"Epsilon value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8234ff",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">num_episodes, run_limit and convergence_criterion</span>\n",
    "\n",
    "The last three options are hyperparameters. They impact computation time. **num_episodes** is the maximum number of epochs used for training. **run_limit** controls the maximum number of iterations before stopping one episode. **convergence_criterion** is the threshold (difference score between two iterations) to determine convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46904f",
   "metadata": {},
   "source": [
    "Before to lunch training. it is important to understand q learning algorithm works in a discretize space. Spacing between each bins can have an impact in convergence. Indeed if for a same discretize space can group too many different states Q table will not be stable and algorithm can have difficulties to converge.\n",
    "\n",
    "Let's see how our space is discretized ``RL.env.json[\"limit\"]``. Agent variable (booster) has 3 bins. In other hand for states variables (\"pos_y\", \"acceleration_y\", \"speed_y\" and \"weight_rocket\") we have 41, 21, 16 and 62 bins.\n",
    "Our Q table is composed of $$ 3 * 41 *21 *21 *62 = 3363066\\  states $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db459391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/1000\n",
      "exploration_prob : 1.000\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -59.28035644799537\n",
      "end while loop iteration :  7\n",
      "Episode 2/1000\n",
      "exploration_prob : 0.985\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -15.145059027596101\n",
      "end while loop iteration :  2\n",
      "Episode 3/1000\n",
      "exploration_prob : 0.970\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -196.58500660513477\n",
      "end while loop iteration :  4\n",
      "Episode 4/1000\n",
      "exploration_prob : 0.956\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -43.73815607412551\n",
      "end while loop iteration :  5\n",
      "Episode 5/1000\n",
      "exploration_prob : 0.942\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -18.0237799724135\n",
      "end while loop iteration :  12\n",
      "Episode 6/1000\n",
      "exploration_prob : 0.928\n",
      "No action possible. Stop episode at 30th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -480.436279532076\n",
      "end while loop iteration :  30\n",
      "Episode 7/1000\n",
      "exploration_prob : 0.914\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -123.41376669448408\n",
      "end while loop iteration :  13\n",
      "Episode 8/1000\n",
      "exploration_prob : 0.900\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -39.06131271370202\n",
      "end while loop iteration :  8\n",
      "Episode 9/1000\n",
      "exploration_prob : 0.887\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -58.789453708000806\n",
      "end while loop iteration :  9\n",
      "Episode 10/1000\n",
      "exploration_prob : 0.874\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -79.92122252614801\n",
      "end while loop iteration :  23\n",
      "Episode 11/1000\n",
      "exploration_prob : 0.861\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -10.749946442630739\n",
      "end while loop iteration :  2\n",
      "Episode 12/1000\n",
      "exploration_prob : 0.848\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -56.80551063100038\n",
      "end while loop iteration :  19\n",
      "Episode 13/1000\n",
      "exploration_prob : 0.835\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -51.112172119145605\n",
      "end while loop iteration :  6\n",
      "Episode 14/1000\n",
      "exploration_prob : 0.823\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -47.75755965018266\n",
      "end while loop iteration :  10\n",
      "Episode 15/1000\n",
      "exploration_prob : 0.811\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -12.563076134894581\n",
      "end while loop iteration :  8\n",
      "Episode 16/1000\n",
      "exploration_prob : 0.799\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.3303990893462469\n",
      "Loss : -10.749946442630739\n",
      "end while loop iteration :  2\n",
      "Episode 17/1000\n",
      "exploration_prob : 0.787\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.7551434953921445\n",
      "Loss : -15.145059027596101\n",
      "end while loop iteration :  2\n",
      "Episode 18/1000\n",
      "exploration_prob : 0.775\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -402.3130113534578\n",
      "end while loop iteration :  14\n",
      "Episode 19/1000\n",
      "exploration_prob : 0.763\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.542269781116873\n",
      "Loss : -62.05416166086243\n",
      "end while loop iteration :  7\n",
      "Episode 20/1000\n",
      "exploration_prob : 0.752\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -62.14713661168777\n",
      "end while loop iteration :  4\n",
      "Episode 21/1000\n",
      "exploration_prob : 0.741\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -276.01988128715834\n",
      "end while loop iteration :  10\n",
      "Episode 22/1000\n",
      "exploration_prob : 0.730\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.8434229383122945\n",
      "Loss : -22.247277596855678\n",
      "end while loop iteration :  6\n",
      "Episode 23/1000\n",
      "exploration_prob : 0.719\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -19.315868136225177\n",
      "end while loop iteration :  6\n",
      "Episode 24/1000\n",
      "exploration_prob : 0.708\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -62.65396361653231\n",
      "end while loop iteration :  10\n",
      "Episode 25/1000\n",
      "exploration_prob : 0.698\n",
      "No action possible. Stop episode at 3th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -15.110865159432858\n",
      "end while loop iteration :  3\n",
      "Episode 26/1000\n",
      "exploration_prob : 0.687\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.29735918041162224\n",
      "Loss : -10.749946442630739\n",
      "end while loop iteration :  2\n",
      "Episode 27/1000\n",
      "exploration_prob : 0.677\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -135.23185606445588\n",
      "end while loop iteration :  14\n",
      "Episode 28/1000\n",
      "exploration_prob : 0.667\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -26.980742796409114\n",
      "end while loop iteration :  5\n",
      "Episode 29/1000\n",
      "exploration_prob : 0.657\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -19.627444742397465\n",
      "end while loop iteration :  6\n",
      "Episode 30/1000\n",
      "exploration_prob : 0.647\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -230.89821879310782\n",
      "end while loop iteration :  13\n",
      "Episode 31/1000\n",
      "exploration_prob : 0.638\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0704981743784492\n",
      "Loss : -17.657958095991024\n",
      "end while loop iteration :  7\n",
      "Episode 32/1000\n",
      "exploration_prob : 0.628\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.67962914585293\n",
      "Loss : -15.145059027596101\n",
      "end while loop iteration :  2\n",
      "Episode 33/1000\n",
      "exploration_prob : 0.619\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -159.82094456604509\n",
      "end while loop iteration :  5\n",
      "Episode 34/1000\n",
      "exploration_prob : 0.610\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  8.9323697840678\n",
      "Loss : -40.468468927359744\n",
      "end while loop iteration :  10\n",
      "Episode 35/1000\n",
      "exploration_prob : 0.600\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -35.46861791875588\n",
      "end while loop iteration :  13\n",
      "Episode 36/1000\n",
      "exploration_prob : 0.592\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -13.944983560415167\n",
      "end while loop iteration :  10\n",
      "Episode 37/1000\n",
      "exploration_prob : 0.583\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  1.93656234196279\n",
      "Loss : -25.610080441707215\n",
      "end while loop iteration :  6\n",
      "Episode 38/1000\n",
      "exploration_prob : 0.574\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  4.409022664896294\n",
      "Loss : -39.420494782288856\n",
      "end while loop iteration :  8\n",
      "Episode 39/1000\n",
      "exploration_prob : 0.566\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -23.35583200600049\n",
      "end while loop iteration :  5\n",
      "Episode 40/1000\n",
      "exploration_prob : 0.557\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -60.517519802355054\n",
      "end while loop iteration :  4\n",
      "Episode 41/1000\n",
      "exploration_prob : 0.549\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -251.40786385324088\n",
      "end while loop iteration :  20\n",
      "Episode 42/1000\n",
      "exploration_prob : 0.541\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.869380265462342\n",
      "Loss : -39.70093410203513\n",
      "end while loop iteration :  6\n",
      "Episode 43/1000\n",
      "exploration_prob : 0.533\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -30.486899460120366\n",
      "end while loop iteration :  9\n",
      "Episode 44/1000\n",
      "exploration_prob : 0.525\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -13.347486977294633\n",
      "end while loop iteration :  8\n",
      "Episode 45/1000\n",
      "exploration_prob : 0.517\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -126.0979840194017\n",
      "end while loop iteration :  6\n",
      "Episode 46/1000\n",
      "exploration_prob : 0.509\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -30.148377550702676\n",
      "end while loop iteration :  10\n",
      "Episode 47/1000\n",
      "exploration_prob : 0.502\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -17.486029160041895\n",
      "end while loop iteration :  6\n",
      "Episode 48/1000\n",
      "exploration_prob : 0.494\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.658367737692151\n",
      "Loss : -92.14063538439292\n",
      "end while loop iteration :  13\n",
      "Episode 49/1000\n",
      "exploration_prob : 0.487\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -16.781231885734915\n",
      "end while loop iteration :  4\n",
      "Episode 50/1000\n",
      "exploration_prob : 0.480\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -11.936818301448252\n",
      "end while loop iteration :  13\n",
      "Episode 51/1000\n",
      "exploration_prob : 0.472\n",
      "No action possible. Stop episode at 3th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.348915805970186\n",
      "Loss : -14.29134639316939\n",
      "end while loop iteration :  3\n",
      "Episode 52/1000\n",
      "exploration_prob : 0.465\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -58.12808567805121\n",
      "end while loop iteration :  9\n",
      "Episode 53/1000\n",
      "exploration_prob : 0.458\n",
      "No action possible. Stop episode at 3th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -47.297541865750546\n",
      "end while loop iteration :  3\n",
      "Episode 54/1000\n",
      "exploration_prob : 0.452\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  12.679852875628104\n",
      "Loss : -74.8800641785179\n",
      "end while loop iteration :  9\n",
      "Episode 55/1000\n",
      "exploration_prob : 0.445\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  29.031294228840324\n",
      "Loss : -127.62763185187221\n",
      "end while loop iteration :  6\n",
      "Episode 56/1000\n",
      "exploration_prob : 0.438\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -33.561087450218324\n",
      "end while loop iteration :  2\n",
      "Episode 57/1000\n",
      "exploration_prob : 0.432\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -19.687470232904772\n",
      "end while loop iteration :  12\n",
      "Episode 58/1000\n",
      "exploration_prob : 0.425\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -119.42139071413526\n",
      "end while loop iteration :  16\n",
      "Episode 59/1000\n",
      "exploration_prob : 0.419\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -18.049420971830223\n",
      "end while loop iteration :  10\n",
      "Episode 60/1000\n",
      "exploration_prob : 0.413\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -100.17693059270884\n",
      "end while loop iteration :  7\n",
      "Episode 61/1000\n",
      "exploration_prob : 0.407\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -21.824289503731347\n",
      "end while loop iteration :  14\n",
      "Episode 62/1000\n",
      "exploration_prob : 0.401\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.07125740522400979\n",
      "Loss : -12.622574111765788\n",
      "end while loop iteration :  8\n",
      "Episode 63/1000\n",
      "exploration_prob : 0.395\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -111.51890286638077\n",
      "end while loop iteration :  11\n",
      "Episode 64/1000\n",
      "exploration_prob : 0.389\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.624088124722415\n",
      "Loss : -101.95649213391782\n",
      "end while loop iteration :  13\n",
      "Episode 65/1000\n",
      "exploration_prob : 0.383\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -12.862334248957502\n",
      "end while loop iteration :  15\n",
      "Episode 66/1000\n",
      "exploration_prob : 0.377\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -37.4180479314872\n",
      "end while loop iteration :  30\n",
      "Episode 67/1000\n",
      "exploration_prob : 0.372\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -20.664797002642672\n",
      "end while loop iteration :  7\n",
      "Episode 68/1000\n",
      "exploration_prob : 0.366\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -415.5395817512038\n",
      "end while loop iteration :  12\n",
      "Episode 69/1000\n",
      "exploration_prob : 0.361\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.115608192968351\n",
      "Loss : -104.30868127408998\n",
      "end while loop iteration :  9\n",
      "Episode 70/1000\n",
      "exploration_prob : 0.355\n",
      "No action possible. Stop episode at 3th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -21.252812308270656\n",
      "end while loop iteration :  3\n",
      "Episode 71/1000\n",
      "exploration_prob : 0.350\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -199.1761932565953\n",
      "end while loop iteration :  7\n",
      "Episode 72/1000\n",
      "exploration_prob : 0.345\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -29.46047868361144\n",
      "end while loop iteration :  17\n",
      "Episode 73/1000\n",
      "exploration_prob : 0.340\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.37935174335094635\n",
      "Loss : -24.56422098660147\n",
      "end while loop iteration :  6\n",
      "Episode 74/1000\n",
      "exploration_prob : 0.335\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -104.63254379259968\n",
      "end while loop iteration :  15\n",
      "Episode 75/1000\n",
      "exploration_prob : 0.330\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -41.18982289423522\n",
      "end while loop iteration :  7\n",
      "Episode 76/1000\n",
      "exploration_prob : 0.325\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -56.32564356458792\n",
      "end while loop iteration :  13\n",
      "Episode 77/1000\n",
      "exploration_prob : 0.320\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -57.30154129275884\n",
      "end while loop iteration :  9\n",
      "Episode 78/1000\n",
      "exploration_prob : 0.315\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -30.702572031528746\n",
      "end while loop iteration :  4\n",
      "Episode 79/1000\n",
      "exploration_prob : 0.310\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -29.724901034960755\n",
      "end while loop iteration :  9\n",
      "Episode 80/1000\n",
      "exploration_prob : 0.306\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -55.46942828257061\n",
      "end while loop iteration :  18\n",
      "Episode 81/1000\n",
      "exploration_prob : 0.301\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  45.419516661815365\n",
      "Loss : -210.90765877352254\n",
      "end while loop iteration :  13\n",
      "Episode 82/1000\n",
      "exploration_prob : 0.297\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -21.64234852968319\n",
      "end while loop iteration :  8\n",
      "Episode 83/1000\n",
      "exploration_prob : 0.292\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -38.697733244756115\n",
      "end while loop iteration :  7\n",
      "Episode 84/1000\n",
      "exploration_prob : 0.288\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -28.113450555332903\n",
      "end while loop iteration :  10\n",
      "Episode 85/1000\n",
      "exploration_prob : 0.284\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.3175311039340025\n",
      "Loss : -56.69968885665597\n",
      "end while loop iteration :  7\n",
      "Episode 86/1000\n",
      "exploration_prob : 0.279\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.0713546770041111\n",
      "Loss : -30.216654218237338\n",
      "end while loop iteration :  5\n",
      "Episode 87/1000\n",
      "exploration_prob : 0.275\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -71.09777444820277\n",
      "end while loop iteration :  16\n",
      "Episode 88/1000\n",
      "exploration_prob : 0.271\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -169.25566132404816\n",
      "end while loop iteration :  14\n",
      "Episode 89/1000\n",
      "exploration_prob : 0.267\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  24.95825695561321\n",
      "Loss : -119.55734586436199\n",
      "end while loop iteration :  11\n",
      "Episode 90/1000\n",
      "exploration_prob : 0.263\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -10.312672532458624\n",
      "end while loop iteration :  12\n",
      "Episode 91/1000\n",
      "exploration_prob : 0.259\n",
      "No action possible. Stop episode at 25th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -283.8787788029882\n",
      "end while loop iteration :  25\n",
      "Episode 92/1000\n",
      "exploration_prob : 0.255\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.2829006727240775\n",
      "Loss : -34.22170372207939\n",
      "end while loop iteration :  9\n",
      "Episode 93/1000\n",
      "exploration_prob : 0.252\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -155.7653129531315\n",
      "end while loop iteration :  10\n",
      "Episode 94/1000\n",
      "exploration_prob : 0.248\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -31.397322370022437\n",
      "end while loop iteration :  12\n",
      "Episode 95/1000\n",
      "exploration_prob : 0.244\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  21.728739484539588\n",
      "Loss : -117.54485665702494\n",
      "end while loop iteration :  15\n",
      "Episode 96/1000\n",
      "exploration_prob : 0.241\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  31.579539549472198\n",
      "Loss : -150.91032359134755\n",
      "end while loop iteration :  14\n",
      "Episode 97/1000\n",
      "exploration_prob : 0.237\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -61.47058692006627\n",
      "end while loop iteration :  6\n",
      "Episode 98/1000\n",
      "exploration_prob : 0.233\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -42.83913581704904\n",
      "end while loop iteration :  16\n",
      "Episode 99/1000\n",
      "exploration_prob : 0.230\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -25.63647424436958\n",
      "end while loop iteration :  8\n",
      "Episode 100/1000\n",
      "exploration_prob : 0.227\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -28.76038493069727\n",
      "end while loop iteration :  20\n",
      "Episode 101/1000\n",
      "exploration_prob : 0.223\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -39.3218586962905\n",
      "end while loop iteration :  6\n",
      "Episode 102/1000\n",
      "exploration_prob : 0.220\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -39.58800824661487\n",
      "end while loop iteration :  8\n",
      "Episode 103/1000\n",
      "exploration_prob : 0.217\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -41.93929635470553\n",
      "end while loop iteration :  20\n",
      "Episode 104/1000\n",
      "exploration_prob : 0.213\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -26.64027846918346\n",
      "end while loop iteration :  20\n",
      "Episode 105/1000\n",
      "exploration_prob : 0.210\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -31.84181899084143\n",
      "end while loop iteration :  12\n",
      "Episode 106/1000\n",
      "exploration_prob : 0.207\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -7.788782177568853\n",
      "end while loop iteration :  13\n",
      "Episode 107/1000\n",
      "exploration_prob : 0.204\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -40.888390787855755\n",
      "end while loop iteration :  11\n",
      "Episode 108/1000\n",
      "exploration_prob : 0.201\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -13.9123457097178\n",
      "end while loop iteration :  11\n",
      "Episode 109/1000\n",
      "exploration_prob : 0.198\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -160.20737007732117\n",
      "end while loop iteration :  14\n",
      "Episode 110/1000\n",
      "exploration_prob : 0.195\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -182.62288549546588\n",
      "end while loop iteration :  17\n",
      "Episode 111/1000\n",
      "exploration_prob : 0.192\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -79.1670459130205\n",
      "end while loop iteration :  12\n",
      "Episode 112/1000\n",
      "exploration_prob : 0.189\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -39.32968232041369\n",
      "end while loop iteration :  14\n",
      "Episode 113/1000\n",
      "exploration_prob : 0.186\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -73.18916110748674\n",
      "end while loop iteration :  18\n",
      "Episode 114/1000\n",
      "exploration_prob : 0.184\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.26762326237045997\n",
      "Loss : -10.749946442630739\n",
      "end while loop iteration :  2\n",
      "Episode 115/1000\n",
      "exploration_prob : 0.181\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.027517281377268256\n",
      "Loss : -22.671042800954787\n",
      "end while loop iteration :  17\n",
      "Episode 116/1000\n",
      "exploration_prob : 0.178\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  22.983305430152903\n",
      "Loss : -100.59829513452249\n",
      "end while loop iteration :  7\n",
      "Episode 117/1000\n",
      "exploration_prob : 0.176\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -44.230411979665426\n",
      "end while loop iteration :  12\n",
      "Episode 118/1000\n",
      "exploration_prob : 0.173\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.5198342159487974\n",
      "Loss : -60.14703110429734\n",
      "end while loop iteration :  6\n",
      "Episode 119/1000\n",
      "exploration_prob : 0.170\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -514.1435127201191\n",
      "end while loop iteration :  22\n",
      "Episode 120/1000\n",
      "exploration_prob : 0.168\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -26.766118285757948\n",
      "end while loop iteration :  15\n",
      "Episode 121/1000\n",
      "exploration_prob : 0.165\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  17.711907331326397\n",
      "Loss : -90.01559798339295\n",
      "end while loop iteration :  12\n",
      "Episode 122/1000\n",
      "exploration_prob : 0.163\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  17.26231182398621\n",
      "Loss : -78.77134301786049\n",
      "end while loop iteration :  12\n",
      "Episode 123/1000\n",
      "exploration_prob : 0.160\n",
      "No action possible. Stop episode at 24th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -46.44431190651185\n",
      "end while loop iteration :  24\n",
      "Episode 124/1000\n",
      "exploration_prob : 0.158\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06494112309900045\n",
      "Loss : -22.677754772926978\n",
      "end while loop iteration :  9\n",
      "Episode 125/1000\n",
      "exploration_prob : 0.156\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -142.2863504229844\n",
      "end while loop iteration :  21\n",
      "Episode 126/1000\n",
      "exploration_prob : 0.153\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  12.447502021148276\n",
      "Loss : -61.464644111037416\n",
      "end while loop iteration :  13\n",
      "Episode 127/1000\n",
      "exploration_prob : 0.151\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  38.29033256165057\n",
      "Loss : -188.83835068710732\n",
      "end while loop iteration :  17\n",
      "Episode 128/1000\n",
      "exploration_prob : 0.149\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -112.3650446753608\n",
      "end while loop iteration :  30\n",
      "Episode 129/1000\n",
      "exploration_prob : 0.147\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -92.25168439329765\n",
      "end while loop iteration :  17\n",
      "Episode 130/1000\n",
      "exploration_prob : 0.144\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  21.247323103966025\n",
      "Loss : -100.73242502301196\n",
      "end while loop iteration :  15\n",
      "Episode 131/1000\n",
      "exploration_prob : 0.142\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.360833195219629\n",
      "Loss : -29.52792960878213\n",
      "end while loop iteration :  11\n",
      "Episode 132/1000\n",
      "exploration_prob : 0.140\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.7096686698987117\n",
      "Loss : -66.61167029766428\n",
      "end while loop iteration :  18\n",
      "Episode 133/1000\n",
      "exploration_prob : 0.138\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.1144612519012185\n",
      "Loss : -18.176383575370814\n",
      "end while loop iteration :  9\n",
      "Episode 134/1000\n",
      "exploration_prob : 0.136\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.086705951353288\n",
      "Loss : -45.74449192211895\n",
      "end while loop iteration :  10\n",
      "Episode 135/1000\n",
      "exploration_prob : 0.134\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.04058741566263817\n",
      "Loss : -32.405842433118636\n",
      "end while loop iteration :  13\n",
      "Episode 136/1000\n",
      "exploration_prob : 0.132\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -54.896816722051184\n",
      "end while loop iteration :  11\n",
      "Episode 137/1000\n",
      "exploration_prob : 0.130\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  39.27149925412326\n",
      "Loss : -189.7110172878027\n",
      "end while loop iteration :  17\n",
      "Episode 138/1000\n",
      "exploration_prob : 0.128\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  6.37281391665062\n",
      "Loss : -38.84346586986716\n",
      "end while loop iteration :  11\n",
      "Episode 139/1000\n",
      "exploration_prob : 0.126\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  4.248839104136764\n",
      "Loss : -24.038991056915165\n",
      "end while loop iteration :  12\n",
      "Episode 140/1000\n",
      "exploration_prob : 0.124\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  37.389510661002625\n",
      "Loss : -199.13053470232148\n",
      "end while loop iteration :  17\n",
      "Episode 141/1000\n",
      "exploration_prob : 0.122\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.0108344923244332\n",
      "Loss : -68.52986371509816\n",
      "end while loop iteration :  8\n",
      "Episode 142/1000\n",
      "exploration_prob : 0.121\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.27102821495843\n",
      "Loss : -45.88050094676956\n",
      "end while loop iteration :  7\n",
      "Episode 143/1000\n",
      "exploration_prob : 0.119\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0167682833009857\n",
      "Loss : -11.985659557062027\n",
      "end while loop iteration :  16\n",
      "Episode 144/1000\n",
      "exploration_prob : 0.117\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -200.57239361621262\n",
      "end while loop iteration :  31\n",
      "Episode 145/1000\n",
      "exploration_prob : 0.115\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6525608570058905\n",
      "Loss : -40.20234553106905\n",
      "end while loop iteration :  12\n",
      "Episode 146/1000\n",
      "exploration_prob : 0.114\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -119.92504852709465\n",
      "end while loop iteration :  11\n",
      "Episode 147/1000\n",
      "exploration_prob : 0.112\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02885353169816239\n",
      "Loss : -39.029617344022405\n",
      "end while loop iteration :  17\n",
      "Episode 148/1000\n",
      "exploration_prob : 0.110\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -35.82583896039063\n",
      "end while loop iteration :  21\n",
      "Episode 149/1000\n",
      "exploration_prob : 0.109\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -38.74015239371885\n",
      "end while loop iteration :  13\n",
      "Episode 150/1000\n",
      "exploration_prob : 0.107\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.0737410049107914\n",
      "Loss : -41.769115691784805\n",
      "end while loop iteration :  16\n",
      "Episode 151/1000\n",
      "exploration_prob : 0.105\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -12.968764536408345\n",
      "end while loop iteration :  14\n",
      "Episode 152/1000\n",
      "exploration_prob : 0.104\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -129.99183995465276\n",
      "end while loop iteration :  6\n",
      "Episode 153/1000\n",
      "exploration_prob : 0.102\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -268.57610227889506\n",
      "end while loop iteration :  8\n",
      "Episode 154/1000\n",
      "exploration_prob : 0.101\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.4054559632955046\n",
      "Loss : -42.61694217873128\n",
      "end while loop iteration :  5\n",
      "Episode 155/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  38.33538657372999\n",
      "Loss : -179.52600126945043\n",
      "end while loop iteration :  17\n",
      "Episode 156/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -47.35835929592082\n",
      "end while loop iteration :  17\n",
      "Episode 157/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -15.100441989785663\n",
      "end while loop iteration :  16\n",
      "Episode 158/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -53.95576162276978\n",
      "end while loop iteration :  20\n",
      "Episode 159/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -305.53051849806275\n",
      "end while loop iteration :  19\n",
      "Episode 160/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.0224864027868044\n",
      "Loss : -46.435868025890336\n",
      "end while loop iteration :  10\n",
      "Episode 161/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.24086093613341397\n",
      "Loss : -10.749946442630739\n",
      "end while loop iteration :  2\n",
      "Episode 162/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -121.07320474404484\n",
      "end while loop iteration :  18\n",
      "Episode 163/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  39.34196418486524\n",
      "Loss : -183.84037487273235\n",
      "end while loop iteration :  17\n",
      "Episode 164/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -76.69657069049268\n",
      "end while loop iteration :  19\n",
      "Episode 165/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -29.396263007601497\n",
      "end while loop iteration :  12\n",
      "Episode 166/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -71.52396593931813\n",
      "end while loop iteration :  11\n",
      "Episode 167/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6612369755338199\n",
      "Loss : -51.67336313944307\n",
      "end while loop iteration :  12\n",
      "Episode 168/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -38.20453103752858\n",
      "end while loop iteration :  31\n",
      "Episode 169/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -117.17018303205188\n",
      "end while loop iteration :  24\n",
      "Episode 170/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -13.468459806211431\n",
      "end while loop iteration :  12\n",
      "Episode 171/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.0206321108489775\n",
      "Loss : -68.91907900002482\n",
      "end while loop iteration :  8\n",
      "Episode 172/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -39.52935753544528\n",
      "end while loop iteration :  21\n",
      "Episode 173/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -205.26141342632167\n",
      "end while loop iteration :  20\n",
      "Episode 174/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.3339575506079464\n",
      "Loss : -70.91402363726735\n",
      "end while loop iteration :  9\n",
      "Episode 175/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -61.96091458829781\n",
      "end while loop iteration :  16\n",
      "Episode 176/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.6378028286493036\n",
      "Loss : -41.72613668616505\n",
      "end while loop iteration :  6\n",
      "Episode 177/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -15.23464327871297\n",
      "end while loop iteration :  17\n",
      "Episode 178/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -76.46676706846866\n",
      "end while loop iteration :  21\n",
      "Episode 179/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 26th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -257.52874460973896\n",
      "end while loop iteration :  26\n",
      "Episode 180/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.5091622751177476\n",
      "Loss : -48.012163317449335\n",
      "end while loop iteration :  8\n",
      "Episode 181/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.0164220273271662\n",
      "Loss : -35.16843391451729\n",
      "end while loop iteration :  10\n",
      "Episode 182/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -140.8484742045122\n",
      "end while loop iteration :  26\n",
      "Episode 183/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 25th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  53.58240903581705\n",
      "Loss : -290.9694067876243\n",
      "end while loop iteration :  25\n",
      "Episode 184/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  32.89490279491957\n",
      "Loss : -152.0084298206074\n",
      "end while loop iteration :  14\n",
      "Episode 185/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -41.966648388273136\n",
      "end while loop iteration :  18\n",
      "Episode 186/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.252909103747597\n",
      "Loss : -38.35360731685285\n",
      "end while loop iteration :  9\n",
      "Episode 187/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -74.70886456548753\n",
      "end while loop iteration :  21\n",
      "Episode 188/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06256215083331437\n",
      "Loss : -8.613903013938398\n",
      "end while loop iteration :  12\n",
      "Episode 189/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  40.949036499697186\n",
      "Loss : -203.00663601053284\n",
      "end while loop iteration :  20\n",
      "Episode 190/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -9.411149186318918\n",
      "end while loop iteration :  11\n",
      "Episode 191/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7289002651557237\n",
      "Loss : -65.20419503112751\n",
      "end while loop iteration :  11\n",
      "Episode 192/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  15.077061239757922\n",
      "Loss : -152.09201807185022\n",
      "end while loop iteration :  19\n",
      "Episode 193/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -111.97556148309248\n",
      "end while loop iteration :  21\n",
      "Episode 194/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.9708166501537087\n",
      "Loss : -46.81600208082483\n",
      "end while loop iteration :  13\n",
      "Episode 195/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -82.55244418506058\n",
      "end while loop iteration :  12\n",
      "Episode 196/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -314.49156983791994\n",
      "end while loop iteration :  16\n",
      "Episode 197/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -12.697041313221156\n",
      "end while loop iteration :  22\n",
      "Episode 198/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  40.952348913985254\n",
      "Loss : -215.53155863835792\n",
      "end while loop iteration :  20\n",
      "Episode 199/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -301.863290016792\n",
      "end while loop iteration :  12\n",
      "Episode 200/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.0934123949460428\n",
      "Loss : -54.92646019868781\n",
      "end while loop iteration :  10\n",
      "Episode 201/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -84.56303858591025\n",
      "end while loop iteration :  15\n",
      "Episode 202/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.8035982085618123\n",
      "Loss : -57.42179590607971\n",
      "end while loop iteration :  12\n",
      "Episode 203/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  8.746139899769986\n",
      "Loss : -47.20798837835953\n",
      "end while loop iteration :  17\n",
      "Episode 204/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  47.54586698869187\n",
      "Loss : -219.7999280385325\n",
      "end while loop iteration :  13\n",
      "Episode 205/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.0638004347122749\n",
      "Loss : -18.50264499584501\n",
      "end while loop iteration :  16\n",
      "Episode 206/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  12.865322248631385\n",
      "Loss : -145.35365534804424\n",
      "end while loop iteration :  12\n",
      "Episode 207/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  9.072412436692316\n",
      "Loss : -72.09382178439989\n",
      "end while loop iteration :  20\n",
      "Episode 208/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06379274760631774\n",
      "Loss : -14.824183615879935\n",
      "end while loop iteration :  21\n",
      "Episode 209/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.287406802458185\n",
      "Loss : -32.2621538780508\n",
      "end while loop iteration :  9\n",
      "Episode 210/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -214.76564750542883\n",
      "end while loop iteration :  23\n",
      "Episode 211/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7418579783323018\n",
      "Loss : -95.3815640954845\n",
      "end while loop iteration :  11\n",
      "Episode 212/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  4.260618741424021\n",
      "Loss : -61.826755555831355\n",
      "end while loop iteration :  12\n",
      "Episode 213/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.04151712853418557\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 214/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -47.06799807158864\n",
      "end while loop iteration :  19\n",
      "Episode 215/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.038412011820636166\n",
      "Loss : -8.287847711596\n",
      "end while loop iteration :  10\n",
      "Episode 216/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.4600760567773005\n",
      "Loss : -51.595249384020285\n",
      "end while loop iteration :  14\n",
      "Episode 217/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  14.444064798628885\n",
      "Loss : -140.0299086958378\n",
      "end while loop iteration :  6\n",
      "Episode 218/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6677032421852855\n",
      "Loss : -19.268696488356873\n",
      "end while loop iteration :  12\n",
      "Episode 219/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -80.1372927085105\n",
      "end while loop iteration :  14\n",
      "Episode 220/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.9829076043841991\n",
      "Loss : -60.30311028765328\n",
      "end while loop iteration :  13\n",
      "Episode 221/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -12.841964895217094\n",
      "end while loop iteration :  11\n",
      "Episode 222/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -74.79047759905308\n",
      "end while loop iteration :  16\n",
      "Episode 223/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6271822314111442\n",
      "Loss : -74.59460830229126\n",
      "end while loop iteration :  12\n",
      "Episode 224/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  8.415532480117946\n",
      "Loss : -53.42006090956026\n",
      "end while loop iteration :  20\n",
      "Episode 225/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  24.59183391442052\n",
      "Loss : -120.79395791446832\n",
      "end while loop iteration :  18\n",
      "Episode 226/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.3695270112569484\n",
      "Loss : -34.75755262484771\n",
      "end while loop iteration :  13\n",
      "Episode 227/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -15.856388496994386\n",
      "end while loop iteration :  28\n",
      "Episode 228/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.8978831573282204\n",
      "Loss : -108.1686336055188\n",
      "end while loop iteration :  12\n",
      "Episode 229/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7848936157741044\n",
      "Loss : -55.37144394324506\n",
      "end while loop iteration :  14\n",
      "Episode 230/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  8.721000616088922\n",
      "Loss : -53.55220947645051\n",
      "end while loop iteration :  17\n",
      "Episode 231/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -23.88599465471507\n",
      "end while loop iteration :  25\n",
      "Episode 232/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.03826219720761296\n",
      "Loss : -11.17074190735789\n",
      "end while loop iteration :  17\n",
      "Episode 233/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  9.086145636133875\n",
      "Loss : -88.30761766781839\n",
      "end while loop iteration :  10\n",
      "Episode 234/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -160.98164136983098\n",
      "end while loop iteration :  13\n",
      "Episode 235/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -32.69467023287949\n",
      "end while loop iteration :  35\n",
      "Episode 236/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -71.13611333721008\n",
      "end while loop iteration :  16\n",
      "Episode 237/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -65.01144667401664\n",
      "end while loop iteration :  11\n",
      "Episode 238/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.784095135122759\n",
      "Loss : -49.08327145720055\n",
      "end while loop iteration :  14\n",
      "Episode 239/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.058458433125068404\n",
      "Loss : -7.378892771070579\n",
      "end while loop iteration :  19\n",
      "Episode 240/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.033524214498703395\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 241/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -15.411918275111907\n",
      "end while loop iteration :  6\n",
      "Episode 242/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6672632626103994\n",
      "Loss : -29.09633904000924\n",
      "end while loop iteration :  6\n",
      "Episode 243/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -205.77575148888582\n",
      "end while loop iteration :  9\n",
      "Episode 244/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -68.22625606211598\n",
      "end while loop iteration :  14\n",
      "Episode 245/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  32.2047350780029\n",
      "Loss : -149.75520890228205\n",
      "end while loop iteration :  14\n",
      "Episode 246/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  40.79350469216819\n",
      "Loss : -211.0097737531781\n",
      "end while loop iteration :  20\n",
      "Episode 247/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.113353784547055\n",
      "Loss : -28.17077129286302\n",
      "end while loop iteration :  9\n",
      "Episode 248/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -65.95629770400781\n",
      "end while loop iteration :  37\n",
      "Episode 249/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -73.91610335764445\n",
      "end while loop iteration :  8\n",
      "Episode 250/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -49.9290972588294\n",
      "end while loop iteration :  23\n",
      "Episode 251/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.030171793048833065\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 252/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.01728134124554085\n",
      "Loss : -15.088803653489384\n",
      "end while loop iteration :  11\n",
      "Episode 253/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -327.74420252871596\n",
      "end while loop iteration :  22\n",
      "Episode 254/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -34.393669865821536\n",
      "end while loop iteration :  15\n",
      "Episode 255/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.286950714466358\n",
      "Loss : -78.5951878648484\n",
      "end while loop iteration :  18\n",
      "Episode 256/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -53.04023227703506\n",
      "end while loop iteration :  15\n",
      "Episode 257/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  4.412380641556697\n",
      "Loss : -23.80932866850693\n",
      "end while loop iteration :  8\n",
      "Episode 258/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -130.52459395200367\n",
      "end while loop iteration :  9\n",
      "Episode 259/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -56.14846688776125\n",
      "end while loop iteration :  27\n",
      "Episode 260/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -10.16740332349774\n",
      "end while loop iteration :  9\n",
      "Episode 261/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -142.2804658509098\n",
      "end while loop iteration :  21\n",
      "Episode 262/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.3157181956054806\n",
      "Loss : -15.578458557635777\n",
      "end while loop iteration :  11\n",
      "Episode 263/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -114.19044050147134\n",
      "end while loop iteration :  22\n",
      "Episode 264/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.836489810859179\n",
      "Loss : -97.42967814591691\n",
      "end while loop iteration :  12\n",
      "Episode 265/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  35.04195740354373\n",
      "Loss : -156.9440896362185\n",
      "end while loop iteration :  10\n",
      "Episode 266/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 24th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -115.16385065030805\n",
      "end while loop iteration :  24\n",
      "Episode 267/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  7.9229831005980405\n",
      "Loss : -59.923785257991824\n",
      "end while loop iteration :  14\n",
      "Episode 268/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.676315333941223\n",
      "Loss : -67.84792227583644\n",
      "end while loop iteration :  8\n",
      "Episode 269/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6789823642657467\n",
      "Loss : -68.25289767402292\n",
      "end while loop iteration :  12\n",
      "Episode 270/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  7.5094156326178325\n",
      "Loss : -44.07282385043695\n",
      "end while loop iteration :  23\n",
      "Episode 271/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.082305421029936\n",
      "Loss : -25.83727656043374\n",
      "end while loop iteration :  15\n",
      "Episode 272/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  4.975594452815134\n",
      "Loss : -30.77033146781061\n",
      "end while loop iteration :  15\n",
      "Episode 273/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05251816690701048\n",
      "Loss : -10.622663262490452\n",
      "end while loop iteration :  24\n",
      "Episode 274/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 25th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -70.93699804531431\n",
      "end while loop iteration :  25\n",
      "Episode 275/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.0824553125542644\n",
      "Loss : -32.74209558682656\n",
      "end while loop iteration :  10\n",
      "Episode 276/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -193.3321523897545\n",
      "end while loop iteration :  19\n",
      "Episode 277/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -111.37292112245578\n",
      "end while loop iteration :  15\n",
      "Episode 278/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -35.369973039156804\n",
      "end while loop iteration :  13\n",
      "Episode 279/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -148.19204518057413\n",
      "end while loop iteration :  21\n",
      "Episode 280/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.027154613743949757\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 281/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7814094702904215\n",
      "Loss : -81.97531297531779\n",
      "end while loop iteration :  11\n",
      "Episode 282/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.42502780746908675\n",
      "Loss : -103.13330294366295\n",
      "end while loop iteration :  14\n",
      "Episode 283/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.024439152369554767\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 284/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -7.740525470194829\n",
      "end while loop iteration :  17\n",
      "Episode 285/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -57.400090144870454\n",
      "end while loop iteration :  18\n",
      "Episode 286/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  11.58121898336804\n",
      "Loss : -59.682618254126574\n",
      "end while loop iteration :  13\n",
      "Episode 287/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 26th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -172.27679432951587\n",
      "end while loop iteration :  26\n",
      "Episode 288/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.620530945152554\n",
      "Loss : -89.99534854663392\n",
      "end while loop iteration :  15\n",
      "Episode 289/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.0752859452959367\n",
      "Loss : -15.950808422939396\n",
      "end while loop iteration :  10\n",
      "Episode 290/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -28.143856288078858\n",
      "end while loop iteration :  14\n",
      "Episode 291/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -36.84247244819589\n",
      "end while loop iteration :  4\n",
      "Episode 292/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.19737613961572442\n",
      "Loss : -10.442378234093697\n",
      "end while loop iteration :  10\n",
      "Episode 293/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -95.10161759915401\n",
      "end while loop iteration :  37\n",
      "Episode 294/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  37.76839441948334\n",
      "Loss : -204.6572357756732\n",
      "end while loop iteration :  23\n",
      "Episode 295/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  4.875865726640511\n",
      "Loss : -58.27554300146777\n",
      "end while loop iteration :  7\n",
      "Episode 296/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0017102759886522129\n",
      "Loss : -47.31763412163768\n",
      "end while loop iteration :  26\n",
      "Episode 297/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05720104915598176\n",
      "Loss : -6.292610340353183\n",
      "end while loop iteration :  17\n",
      "Episode 298/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 30th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -309.607719646557\n",
      "end while loop iteration :  30\n",
      "Episode 299/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -14.724623879405767\n",
      "end while loop iteration :  17\n",
      "Episode 300/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  65.56740253616299\n",
      "Loss : -369.12275585847215\n",
      "end while loop iteration :  22\n",
      "Episode 301/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02456272166563187\n",
      "Loss : -10.136264485099328\n",
      "end while loop iteration :  14\n",
      "Episode 302/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -152.97189079074764\n",
      "end while loop iteration :  38\n",
      "Episode 303/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.7606708394857425\n",
      "Loss : -23.511495370968937\n",
      "end while loop iteration :  18\n",
      "Episode 304/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 63th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -298.85969752586135\n",
      "end while loop iteration :  63\n",
      "Episode 305/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.021995237132599293\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 306/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -76.10069550791134\n",
      "end while loop iteration :  22\n",
      "Episode 307/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 24th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  21.417178570728037\n",
      "Loss : -130.77046668681635\n",
      "end while loop iteration :  24\n",
      "Episode 308/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -101.9789201142765\n",
      "end while loop iteration :  14\n",
      "Episode 309/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 3th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.31268141690283435\n",
      "Loss : -15.110865159432858\n",
      "end while loop iteration :  3\n",
      "Episode 310/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.7718463332193816\n",
      "Loss : -9.942008624294374\n",
      "end while loop iteration :  18\n",
      "Episode 311/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.01979571341933936\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 312/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -24.471516808153897\n",
      "end while loop iteration :  18\n",
      "Episode 313/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 24th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.807994939484666\n",
      "Loss : -139.04523981570372\n",
      "end while loop iteration :  24\n",
      "Episode 314/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.3033738072693528\n",
      "Loss : -47.00058204359706\n",
      "end while loop iteration :  7\n",
      "Episode 315/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -72.587632421258\n",
      "end while loop iteration :  39\n",
      "Episode 316/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.038884672294354966\n",
      "Loss : -12.328354926686405\n",
      "end while loop iteration :  18\n",
      "Episode 317/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06406534798610569\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 318/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.9784832406190938\n",
      "Loss : -70.89279670184642\n",
      "end while loop iteration :  12\n",
      "Episode 319/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6272927932367959\n",
      "Loss : -45.137003263742045\n",
      "end while loop iteration :  15\n",
      "Episode 320/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 27th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -107.99678536900763\n",
      "end while loop iteration :  27\n",
      "Episode 321/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -207.84264999457957\n",
      "end while loop iteration :  15\n",
      "Episode 322/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -63.92120885008906\n",
      "end while loop iteration :  29\n",
      "Episode 323/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.9755990510484305\n",
      "Loss : -100.76997112608636\n",
      "end while loop iteration :  13\n",
      "Episode 324/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.024500336526622424\n",
      "Loss : -7.478899909534824\n",
      "end while loop iteration :  14\n",
      "Episode 325/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  59.49953069952501\n",
      "Loss : -276.5386524507344\n",
      "end while loop iteration :  16\n",
      "Episode 326/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 28th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -60.86759298649622\n",
      "end while loop iteration :  28\n",
      "Episode 327/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0011877508639088624\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 328/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.6163684876075213\n",
      "Loss : -21.00010030194337\n",
      "end while loop iteration :  14\n",
      "Episode 329/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.5809307772005671\n",
      "Loss : -32.73399324754729\n",
      "end while loop iteration :  6\n",
      "Episode 330/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.016401553951860715\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 331/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0709524466216613\n",
      "Loss : -20.69211209376095\n",
      "end while loop iteration :  8\n",
      "Episode 332/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 24th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  22.014883790491975\n",
      "Loss : -114.55438539150987\n",
      "end while loop iteration :  24\n",
      "Episode 333/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.03446970910088773\n",
      "Loss : -18.012244548099822\n",
      "end while loop iteration :  14\n",
      "Episode 334/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 26th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.903332260585612\n",
      "Loss : -66.01231590626166\n",
      "end while loop iteration :  26\n",
      "Episode 335/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.01580799469654376\n",
      "Loss : -8.287847711596\n",
      "end while loop iteration :  10\n",
      "Episode 336/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -169.4914012528957\n",
      "end while loop iteration :  59\n",
      "Episode 337/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  6.210767567299644\n",
      "Loss : -30.883471419407726\n",
      "end while loop iteration :  11\n",
      "Episode 338/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.7454590017623671\n",
      "Loss : -59.817522038216666\n",
      "end while loop iteration :  17\n",
      "Episode 339/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -43.89163998046903\n",
      "end while loop iteration :  31\n",
      "Episode 340/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -96.80842570895243\n",
      "end while loop iteration :  22\n",
      "Episode 341/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6786660059194853\n",
      "Loss : -46.513109153985184\n",
      "end while loop iteration :  15\n",
      "Episode 342/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 34th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -94.10148824642945\n",
      "end while loop iteration :  34\n",
      "Episode 343/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.0531004059740519\n",
      "Loss : -61.15656081005332\n",
      "end while loop iteration :  16\n",
      "Episode 344/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -21.823775861692084\n",
      "end while loop iteration :  14\n",
      "Episode 345/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 26th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  32.21257964741943\n",
      "Loss : -179.6231360647697\n",
      "end while loop iteration :  26\n",
      "Episode 346/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  4.07148607099426\n",
      "Loss : -35.16910181234637\n",
      "end while loop iteration :  9\n",
      "Episode 347/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -9.624075392664587\n",
      "end while loop iteration :  15\n",
      "Episode 348/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.6476457337060689\n",
      "Loss : -38.27900200169466\n",
      "end while loop iteration :  12\n",
      "Episode 349/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0630437100419774\n",
      "Loss : -10.26386414475042\n",
      "end while loop iteration :  21\n",
      "Episode 350/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0761947359384555\n",
      "Loss : -22.77166997184993\n",
      "end while loop iteration :  9\n",
      "Episode 351/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  4.381330714716949\n",
      "Loss : -23.97853441059971\n",
      "end while loop iteration :  8\n",
      "Episode 352/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.01318059908702024\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 353/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  5.467023779760002\n",
      "Loss : -34.49148550549766\n",
      "end while loop iteration :  18\n",
      "Episode 354/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -177.82436012534575\n",
      "end while loop iteration :  43\n",
      "Episode 355/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.5113943724365315\n",
      "Loss : -79.97367455138208\n",
      "end while loop iteration :  5\n",
      "Episode 356/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -125.59801860754206\n",
      "end while loop iteration :  48\n",
      "Episode 357/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.011862539178318199\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 358/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.924845303237136\n",
      "Loss : -72.81592252318184\n",
      "end while loop iteration :  9\n",
      "Episode 359/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.4355963210152853\n",
      "Loss : -23.696671527080436\n",
      "end while loop iteration :  10\n",
      "Episode 360/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0010689757775179769\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 361/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -187.98656817956694\n",
      "end while loop iteration :  17\n",
      "Episode 362/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.271458986535293\n",
      "Loss : -31.85689770325826\n",
      "end while loop iteration :  18\n",
      "Episode 363/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05598846630280224\n",
      "Loss : -9.992181998594354\n",
      "end while loop iteration :  12\n",
      "Episode 364/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.39159986316423323\n",
      "Loss : -20.937418877164113\n",
      "end while loop iteration :  7\n",
      "Episode 365/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.07218823134426276\n",
      "Loss : -8.613744994058301\n",
      "end while loop iteration :  12\n",
      "Episode 366/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.8603241053974129\n",
      "Loss : -14.996670380558069\n",
      "end while loop iteration :  10\n",
      "Episode 367/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.024842265714301093\n",
      "Loss : -14.436321872808765\n",
      "end while loop iteration :  12\n",
      "Episode 368/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.039879590451541\n",
      "Loss : -80.71721114438222\n",
      "end while loop iteration :  13\n",
      "Episode 369/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.07535473893464135\n",
      "Loss : -6.509978321486641\n",
      "end while loop iteration :  13\n",
      "Episode 370/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.38401992070210267\n",
      "Loss : -37.389295556575256\n",
      "end while loop iteration :  19\n",
      "Episode 371/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -52.6051259701009\n",
      "end while loop iteration :  21\n",
      "Episode 372/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -94.08408342726882\n",
      "end while loop iteration :  5\n",
      "Episode 373/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -51.22769052419953\n",
      "end while loop iteration :  41\n",
      "Episode 374/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.008350614821891662\n",
      "Loss : -17.088562716898863\n",
      "end while loop iteration :  20\n",
      "Episode 375/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 25th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  11.484365254582311\n",
      "Loss : -61.35431759326174\n",
      "end while loop iteration :  25\n",
      "Episode 376/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.009963924083080888\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 377/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.7936296402566075\n",
      "Loss : -48.31068054132216\n",
      "end while loop iteration :  15\n",
      "Episode 378/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05264783021380681\n",
      "Loss : -6.521150243727881\n",
      "end while loop iteration :  19\n",
      "Episode 379/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.04733860423491526\n",
      "Loss : -7.563357479659793\n",
      "end while loop iteration :  19\n",
      "Episode 380/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 5th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.961578189258642\n",
      "Loss : -30.216654218237338\n",
      "end while loop iteration :  5\n",
      "Episode 381/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.04287936733412928\n",
      "Loss : -15.571653434192056\n",
      "end while loop iteration :  19\n",
      "Episode 382/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.611004188807174\n",
      "Loss : -56.57895600189279\n",
      "end while loop iteration :  22\n",
      "Episode 383/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.865534950336184\n",
      "Loss : -52.47405283408493\n",
      "end while loop iteration :  12\n",
      "Episode 384/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.0359045682349173\n",
      "Loss : -91.24383929270374\n",
      "end while loop iteration :  15\n",
      "Episode 385/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.3188889903663979\n",
      "Loss : -13.826892277971776\n",
      "end while loop iteration :  7\n",
      "Episode 386/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -99.3372910263208\n",
      "end while loop iteration :  35\n",
      "Episode 387/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.005611961912413893\n",
      "Loss : -11.26861575110873\n",
      "end while loop iteration :  14\n",
      "Episode 388/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.995580215419497\n",
      "Loss : -59.59703449732621\n",
      "end while loop iteration :  9\n",
      "Episode 389/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 25th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  55.27167274519967\n",
      "Loss : -311.70654023523616\n",
      "end while loop iteration :  25\n",
      "Episode 390/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  14.434681547092408\n",
      "Loss : -76.80477257415833\n",
      "end while loop iteration :  19\n",
      "Episode 391/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.2866839539826853\n",
      "Loss : -31.175469105983883\n",
      "end while loop iteration :  11\n",
      "Episode 392/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.0157855164615164\n",
      "Loss : -31.028301425887186\n",
      "end while loop iteration :  19\n",
      "Episode 393/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -13.566716153375857\n",
      "end while loop iteration :  10\n",
      "Episode 394/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  7.901697222366903\n",
      "Loss : -50.84934234121663\n",
      "end while loop iteration :  23\n",
      "Episode 395/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.0838522373600323\n",
      "Loss : -99.97098635716137\n",
      "end while loop iteration :  9\n",
      "Episode 396/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.09602108299405097\n",
      "Loss : -9.292629802348324\n",
      "end while loop iteration :  20\n",
      "Episode 397/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.008968729731606721\n",
      "Loss : -13.141426273241025\n",
      "end while loop iteration :  17\n",
      "Episode 398/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  24.02244252730646\n",
      "Loss : -135.6709888684057\n",
      "end while loop iteration :  21\n",
      "Episode 399/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0009620781997661774\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 400/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.0237079153847357\n",
      "Loss : -52.641292222255736\n",
      "end while loop iteration :  13\n",
      "Episode 401/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.43928288788493486\n",
      "Loss : -23.7352951698418\n",
      "end while loop iteration :  8\n",
      "Episode 402/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 2th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.0532747630225443\n",
      "Loss : -33.561087450218324\n",
      "end while loop iteration :  2\n",
      "Episode 403/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  13.89902972756719\n",
      "Loss : -74.3352591554321\n",
      "end while loop iteration :  16\n",
      "Episode 404/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7822614809603594\n",
      "Loss : -81.51192425570235\n",
      "end while loop iteration :  11\n",
      "Episode 405/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -75.13207056200923\n",
      "end while loop iteration :  32\n",
      "Episode 406/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 34th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.979870053811883\n",
      "Loss : -75.65197828358836\n",
      "end while loop iteration :  34\n",
      "Episode 407/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.003930356169133675\n",
      "Loss : -10.491578204774669\n",
      "end while loop iteration :  14\n",
      "Episode 408/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.40988319579794574\n",
      "Loss : -16.781231885734915\n",
      "end while loop iteration :  4\n",
      "Episode 409/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -14.709767156241616\n",
      "end while loop iteration :  12\n",
      "Episode 410/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  21.042019583903205\n",
      "Loss : -204.2861699218059\n",
      "end while loop iteration :  10\n",
      "Episode 411/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -107.49797976243602\n",
      "end while loop iteration :  30\n",
      "Episode 412/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.009462059135610323\n",
      "Loss : -8.287847711596\n",
      "end while loop iteration :  10\n",
      "Episode 413/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06141486798478671\n",
      "Loss : -10.355085769393726\n",
      "end while loop iteration :  13\n",
      "Episode 414/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0746218958524448\n",
      "Loss : -12.22376618864\n",
      "end while loop iteration :  8\n",
      "Episode 415/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.07265707011895893\n",
      "Loss : -9.07767722117753\n",
      "end while loop iteration :  17\n",
      "Episode 416/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  37.65302834717262\n",
      "Loss : -203.18553577836025\n",
      "end while loop iteration :  23\n",
      "Episode 417/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.9945181592212777\n",
      "Loss : -21.70540746251866\n",
      "end while loop iteration :  19\n",
      "Episode 418/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -72.74293940442607\n",
      "end while loop iteration :  18\n",
      "Episode 419/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06732995375681855\n",
      "Loss : -7.378892771070579\n",
      "end while loop iteration :  19\n",
      "Episode 420/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.06414073138238954\n",
      "Loss : -8.740169907962676\n",
      "end while loop iteration :  10\n",
      "Episode 421/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.655979760701444\n",
      "Loss : -114.23091149671701\n",
      "end while loop iteration :  6\n",
      "Episode 422/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  8.774500125896912\n",
      "Loss : -50.68503545792241\n",
      "end while loop iteration :  20\n",
      "Episode 423/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0008658703797895587\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 424/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.007057491288230133\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 425/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.006351742159407092\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 426/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -46.37024889624121\n",
      "end while loop iteration :  14\n",
      "Episode 427/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.1084449543585142\n",
      "Loss : -109.71632351949363\n",
      "end while loop iteration :  16\n",
      "Episode 428/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.026229749168117794\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 429/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -633.587075153701\n",
      "end while loop iteration :  15\n",
      "Episode 430/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -8.651737968820443\n",
      "end while loop iteration :  18\n",
      "Episode 431/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.4004456557313944\n",
      "Loss : -71.34889227093855\n",
      "end while loop iteration :  19\n",
      "Episode 432/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02326599530549628\n",
      "Loss : -7.728279906554319\n",
      "end while loop iteration :  12\n",
      "Episode 433/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.005716567943466422\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 434/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.7788117866763561\n",
      "Loss : -78.49461717199708\n",
      "end while loop iteration :  17\n",
      "Episode 435/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 28th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -150.1683736387743\n",
      "end while loop iteration :  28\n",
      "Episode 436/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06781926504117723\n",
      "Loss : -6.509978321486641\n",
      "end while loop iteration :  13\n",
      "Episode 437/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.061011884486972257\n",
      "Loss : -7.104091616131929\n",
      "end while loop iteration :  13\n",
      "Episode 438/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.03344565835834441\n",
      "Loss : -14.45483595860454\n",
      "end while loop iteration :  15\n",
      "Episode 439/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.275202902887062\n",
      "Loss : -43.40573586473997\n",
      "end while loop iteration :  6\n",
      "Episode 440/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.03403445852404316\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 441/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  1.9407813388127693\n",
      "Loss : -19.570506319663902\n",
      "end while loop iteration :  6\n",
      "Episode 442/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  21.717067678609666\n",
      "Loss : -111.03410638477303\n",
      "end while loop iteration :  15\n",
      "Episode 443/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  7.756050875916168\n",
      "Loss : -108.98891484698831\n",
      "end while loop iteration :  11\n",
      "Episode 444/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.005144911149119746\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 445/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.004630420034207772\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 446/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  6.492632897451154\n",
      "Loss : -139.85702928423322\n",
      "end while loop iteration :  15\n",
      "Episode 447/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.091877885200893\n",
      "Loss : -52.383068365066904\n",
      "end while loop iteration :  9\n",
      "Episode 448/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02766133452182799\n",
      "Loss : -14.30614981288038\n",
      "end while loop iteration :  34\n",
      "Episode 449/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0422462030302396\n",
      "Loss : -7.059033924527069\n",
      "end while loop iteration :  17\n",
      "Episode 450/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -86.18825349496808\n",
      "end while loop iteration :  16\n",
      "Episode 451/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.5591138468664991\n",
      "Loss : -81.80691500981621\n",
      "end while loop iteration :  18\n",
      "Episode 452/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0392198482786813\n",
      "Loss : -17.857084891344723\n",
      "end while loop iteration :  15\n",
      "Episode 453/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  24.08108232870999\n",
      "Loss : -126.48180911941435\n",
      "end while loop iteration :  21\n",
      "Episode 454/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06205758279575477\n",
      "Loss : -7.203540577598318\n",
      "end while loop iteration :  19\n",
      "Episode 455/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.9938624106774472\n",
      "Loss : -36.617773320824924\n",
      "end while loop iteration :  13\n",
      "Episode 456/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.03647813167110381\n",
      "Loss : -8.613744994058301\n",
      "end while loop iteration :  12\n",
      "Episode 457/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.004167378030787039\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 458/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.003750640227708324\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 459/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.026429998717908083\n",
      "Loss : -20.196123073936313\n",
      "end while loop iteration :  17\n",
      "Episode 460/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -43.74634255821207\n",
      "end while loop iteration :  20\n",
      "Episode 461/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.06208868345426706\n",
      "Loss : -9.881371460813469\n",
      "end while loop iteration :  25\n",
      "Episode 462/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.054391200101561225\n",
      "Loss : -7.378892771070579\n",
      "end while loop iteration :  19\n",
      "Episode 463/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.047213043698190106\n",
      "Loss : -10.685563721222723\n",
      "end while loop iteration :  24\n",
      "Episode 464/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  1.4714430155505556\n",
      "Loss : -18.067827490738676\n",
      "end while loop iteration :  20\n",
      "Episode 465/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 15th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  22.316845396447192\n",
      "Loss : -107.82613171174631\n",
      "end while loop iteration :  15\n",
      "Episode 466/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.003375576204937447\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 467/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  3.12744122060361\n",
      "Loss : -22.776757387594515\n",
      "end while loop iteration :  19\n",
      "Episode 468/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.002693650353594687\n",
      "Loss : -10.805579894572192\n",
      "end while loop iteration :  14\n",
      "Episode 469/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.041974360681623794\n",
      "Loss : -7.970598744941361\n",
      "end while loop iteration :  14\n",
      "Episode 470/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.03915106622880829\n",
      "Loss : -10.559740851427769\n",
      "end while loop iteration :  19\n",
      "Episode 471/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.644898110565693\n",
      "Loss : -49.28728386330588\n",
      "end while loop iteration :  6\n",
      "Episode 472/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.003038018584443747\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 473/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0027342167259993833\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 474/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.003288382097212536\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 475/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -152.07979729859636\n",
      "end while loop iteration :  17\n",
      "Episode 476/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.2889358905725436\n",
      "Loss : -31.92760373629521\n",
      "end while loop iteration :  11\n",
      "Episode 477/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.14441539398497455\n",
      "Loss : -13.695854649825932\n",
      "end while loop iteration :  22\n",
      "Episode 478/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -15.977090518417432\n",
      "end while loop iteration :  15\n",
      "Episode 479/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0027897041223523544\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 480/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 29th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -177.55404846026866\n",
      "end while loop iteration :  29\n",
      "Episode 481/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05087030205824736\n",
      "Loss : -9.725900174439667\n",
      "end while loop iteration :  19\n",
      "Episode 482/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  21.617496317667857\n",
      "Loss : -261.552776370389\n",
      "end while loop iteration :  10\n",
      "Episode 483/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.4215946091835256\n",
      "Loss : -68.24761355723916\n",
      "end while loop iteration :  18\n",
      "Episode 484/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  6.020701144028149\n",
      "Loss : -130.11602859671729\n",
      "end while loop iteration :  20\n",
      "Episode 485/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0039059981308579572\n",
      "Loss : -10.47104974780006\n",
      "end while loop iteration :  10\n",
      "Episode 486/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0021201338970313066\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 487/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.1027162826290535\n",
      "Loss : -77.98099591686595\n",
      "end while loop iteration :  21\n",
      "Episode 488/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.07906572636088126\n",
      "Loss : -9.305582330718298\n",
      "end while loop iteration :  10\n",
      "Episode 489/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02944643982904574\n",
      "Loss : -6.096347250963901\n",
      "end while loop iteration :  21\n",
      "Episode 490/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0019081205073281926\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 491/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7563033897758942\n",
      "Loss : -68.31934766608549\n",
      "end while loop iteration :  14\n",
      "Episode 492/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.035995786293798904\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 493/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -76.68855995356842\n",
      "end while loop iteration :  22\n",
      "Episode 494/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0017173084565953456\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 495/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0015455776109358221\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 496/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.5408815511015881\n",
      "Loss : -39.70093410203513\n",
      "end while loop iteration :  6\n",
      "Episode 497/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.007929737843875174\n",
      "Loss : -13.240941176518074\n",
      "end while loop iteration :  17\n",
      "Episode 498/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.005490810919711153\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 499/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 30th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  56.23024024199228\n",
      "Loss : -312.2274739394621\n",
      "end while loop iteration :  30\n",
      "Episode 500/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.002044946892578281\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 501/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.027314085597206383\n",
      "Loss : -11.938463124163839\n",
      "end while loop iteration :  21\n",
      "Episode 502/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  10.731617709922233\n",
      "Loss : -87.77777819006992\n",
      "end while loop iteration :  8\n",
      "Episode 503/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 20th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -80.23919819085259\n",
      "end while loop iteration :  20\n",
      "Episode 504/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0018404522033204085\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 505/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -97.58967704160882\n",
      "end while loop iteration :  22\n",
      "Episode 506/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.012334630565367571\n",
      "Loss : -6.469735489049649\n",
      "end while loop iteration :  14\n",
      "Episode 507/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.25456238685633875\n",
      "Loss : -14.073770478165084\n",
      "end while loop iteration :  17\n",
      "Episode 508/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 9th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.9489937538715325\n",
      "Loss : -56.717406726789775\n",
      "end while loop iteration :  9\n",
      "Episode 509/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.028884550925342135\n",
      "Loss : -12.623116043693214\n",
      "end while loop iteration :  16\n",
      "Episode 510/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.001656406982988412\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 511/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0014907662846895264\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 512/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.4737545368223781\n",
      "Loss : -26.19133513942251\n",
      "end while loop iteration :  4\n",
      "Episode 513/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0013416896562206126\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 514/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0012075206905985403\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 515/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 4th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.7674655683145186\n",
      "Loss : -57.16609388236495\n",
      "end while loop iteration :  4\n",
      "Episode 516/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 23th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  7.334299821089889\n",
      "Loss : -118.1411845687351\n",
      "end while loop iteration :  23\n",
      "Episode 517/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05487277968254867\n",
      "Loss : -8.692529058913527\n",
      "end while loop iteration :  13\n",
      "Episode 518/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05355905819825174\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 519/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 12th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  12.84027674016326\n",
      "Loss : -174.4252933961324\n",
      "end while loop iteration :  12\n",
      "Episode 520/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0010867686215386696\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 521/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0009780917593847915\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 522/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 37th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -170.19783036244755\n",
      "end while loop iteration :  37\n",
      "Episode 523/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0008802825834463568\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 524/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  10.708663300192361\n",
      "Loss : -192.18392950699595\n",
      "end while loop iteration :  17\n",
      "Episode 525/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.032396207664418974\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 526/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -117.37231207740979\n",
      "end while loop iteration :  22\n",
      "Episode 527/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -330.71544912396615\n",
      "end while loop iteration :  18\n",
      "Episode 528/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0007922543251017156\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 529/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02418484724989213\n",
      "Loss : -13.38126790396849\n",
      "end while loop iteration :  16\n",
      "Episode 530/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.3786580021040492\n",
      "Loss : -95.59857407027565\n",
      "end while loop iteration :  21\n",
      "Episode 531/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.023280454480343757\n",
      "Loss : -11.985659557062027\n",
      "end while loop iteration :  16\n",
      "Episode 532/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0007130288925915051\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 533/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.000641726003332399\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 534/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.985606581492671\n",
      "Loss : -19.605321595367116\n",
      "end while loop iteration :  16\n",
      "Episode 535/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0005775534029991425\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 536/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0005197980626991949\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 537/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.012735441873989006\n",
      "Loss : -7.478899909534824\n",
      "end while loop iteration :  14\n",
      "Episode 538/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02407064022692967\n",
      "Loss : -14.440854386859987\n",
      "end while loop iteration :  17\n",
      "Episode 539/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 25th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  55.29554000247373\n",
      "Loss : -345.42276843308\n",
      "end while loop iteration :  25\n",
      "Episode 540/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  11.376375177558193\n",
      "Loss : -53.69612332636693\n",
      "end while loop iteration :  13\n",
      "Episode 541/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00046781825642927544\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 542/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0004210364307863923\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 543/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00037893278770773087\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 544/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.669343765455628\n",
      "Loss : -25.78567317032817\n",
      "end while loop iteration :  21\n",
      "Episode 545/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 13th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.014142205972047\n",
      "Loss : -55.50179597211681\n",
      "end while loop iteration :  13\n",
      "Episode 546/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.1320912266474512\n",
      "Loss : -98.32293121679301\n",
      "end while loop iteration :  16\n",
      "Episode 547/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0003410395089369356\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 548/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00030693555804328643\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 549/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0002762420022389689\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 550/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0002486178020150165\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 551/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  3.696271391477483\n",
      "Loss : -114.33427508985504\n",
      "end while loop iteration :  18\n",
      "Episode 552/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.4493135956888152\n",
      "Loss : -37.53906731844761\n",
      "end while loop iteration :  16\n",
      "Episode 553/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00022375602181357035\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 554/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0002013804196321911\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 555/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00018124237766897755\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 556/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 7th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -33.83207394302624\n",
      "end while loop iteration :  7\n",
      "Episode 557/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -219.2135377843747\n",
      "end while loop iteration :  54\n",
      "Episode 558/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00016311813990205204\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 559/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0001468063259118524\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 560/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -135.72889442533867\n",
      "end while loop iteration :  36\n",
      "Episode 561/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0001321256933206616\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 562/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00011891312398859544\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 563/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02915658689797712\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 564/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0763679440866425\n",
      "Loss : -9.575721602413495\n",
      "end while loop iteration :  15\n",
      "Episode 565/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00010702181158972479\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 566/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  9.631963043077452e-05\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 567/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.05208914266175049\n",
      "Loss : -8.304329115771349\n",
      "end while loop iteration :  14\n",
      "Episode 568/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 10th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.057726658244150575\n",
      "Loss : -8.740169907962676\n",
      "end while loop iteration :  10\n",
      "Episode 569/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 8th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  16.801882735112684\n",
      "Loss : -75.13972402901847\n",
      "end while loop iteration :  8\n",
      "Episode 570/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02377038728642053\n",
      "Loss : -6.096347250963901\n",
      "end while loop iteration :  21\n",
      "Episode 571/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  8.668766738773037e-05\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 572/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.006348852551476325\n",
      "Loss : -6.509978321486641\n",
      "end while loop iteration :  13\n",
      "Episode 573/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -429.4874203845709\n",
      "end while loop iteration :  19\n",
      "Episode 574/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  7.801890064895733e-05\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 575/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  1.859213646381357\n",
      "Loss : -8.245823711421224\n",
      "end while loop iteration :  11\n",
      "Episode 576/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.026736711071703334\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 577/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -176.196592134538\n",
      "end while loop iteration :  21\n",
      "Episode 578/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  15.957035445559825\n",
      "Loss : -125.3656507051347\n",
      "end while loop iteration :  14\n",
      "Episode 579/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.024063039964533017\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 580/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02165673596807971\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 581/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 14th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.8079328752968704\n",
      "Loss : -85.11993281471466\n",
      "end while loop iteration :  14\n",
      "Episode 582/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.07049223642682373\n",
      "Loss : -20.103681971202867\n",
      "end while loop iteration :  15\n",
      "Episode 583/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.01949106237127174\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 584/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.017541956134144554\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 585/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.015787760520730054\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 586/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.014208984468657038\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 587/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 21th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  2.117245252470216\n",
      "Loss : -235.34599817379254\n",
      "end while loop iteration :  21\n",
      "Episode 588/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.009002270448289412\n",
      "Loss : -12.674180116570227\n",
      "end while loop iteration :  14\n",
      "Episode 589/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.012788086021791378\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 590/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.008842243693327978\n",
      "Loss : -10.950712274258386\n",
      "end while loop iteration :  14\n",
      "Episode 591/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.011509277419612274\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 592/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00571396729632867\n",
      "Loss : -6.509978321486641\n",
      "end while loop iteration :  13\n",
      "Episode 593/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0209425000297581\n",
      "Loss : -14.36322514026799\n",
      "end while loop iteration :  16\n",
      "Episode 594/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -87.83946494127476\n",
      "end while loop iteration :  19\n",
      "Episode 595/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.010358349677651035\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 596/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 22th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.9129457119291555\n",
      "Loss : -119.76232141447599\n",
      "end while loop iteration :  22\n",
      "Episode 597/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.009322514709885876\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 598/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -32.1157528486274\n",
      "end while loop iteration :  25\n",
      "Episode 599/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.008390263238897355\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 600/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.007551236915007586\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 601/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.006796113223506817\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 602/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.002351974321786049\n",
      "Loss : -19.255642366908745\n",
      "end while loop iteration :  14\n",
      "Episode 603/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 28th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -366.51160699823845\n",
      "end while loop iteration :  28\n",
      "Episode 604/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.032257971425525056\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 605/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  5.678205364343867\n",
      "Loss : -100.74161877482283\n",
      "end while loop iteration :  16\n",
      "Episode 606/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.006116501901156202\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 607/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "Q table still growths\n",
      "Loss : -106.57336868410668\n",
      "end while loop iteration :  25\n",
      "Episode 608/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.029032174282972556\n",
      "Loss : -6.182763896468927\n",
      "end while loop iteration :  12\n",
      "Episode 609/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.005504851711040537\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 610/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 6th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.30435142713714713\n",
      "Loss : -17.90392035482396\n",
      "end while loop iteration :  6\n",
      "Episode 611/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.004954366539936528\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 612/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 30th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -144.21564678404263\n",
      "end while loop iteration :  30\n",
      "Episode 613/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 3th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.28275608368288396\n",
      "Loss : -14.29134639316939\n",
      "end while loop iteration :  3\n",
      "Episode 614/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 24th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -29.865419049430162\n",
      "end while loop iteration :  24\n",
      "Episode 615/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 32th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -77.11613718982207\n",
      "end while loop iteration :  32\n",
      "Episode 616/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.004458929885942764\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 617/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 17th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  8.766828526550189\n",
      "Loss : -57.90170450072472\n",
      "end while loop iteration :  17\n",
      "Episode 618/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 11th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.5145539165804653\n",
      "Loss : -44.82022828608888\n",
      "end while loop iteration :  11\n",
      "Episode 619/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.004013036897348554\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 620/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.014902180849678898\n",
      "Loss : -6.469735489049649\n",
      "end while loop iteration :  14\n",
      "Episode 621/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0036117332076136544\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 622/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0032505598868523\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 623/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.4744769481655513\n",
      "Loss : -102.83813507989993\n",
      "end while loop iteration :  18\n",
      "Episode 624/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0029255038981670367\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 625/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.039302859599447654\n",
      "Loss : -34.762340185058115\n",
      "end while loop iteration :  16\n",
      "Episode 626/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0026329535083503552\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 627/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 16th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -113.05526670573998\n",
      "end while loop iteration :  16\n",
      "Episode 628/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.002369658157515331\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 629/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.002132692341763831\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 630/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.6038816444693402\n",
      "Loss : -14.226802747689147\n",
      "end while loop iteration :  35\n",
      "Episode 631/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.038639271504660316\n",
      "Loss : -6.674816674593676\n",
      "end while loop iteration :  21\n",
      "Episode 632/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0019194231075874146\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 633/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.056470682853199554\n",
      "Loss : -9.77935656612143\n",
      "end while loop iteration :  25\n",
      "Episode 634/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0017274807968287176\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 635/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 18th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  0.7843110095131487\n",
      "Loss : -35.60077576306621\n",
      "end while loop iteration :  18\n",
      "Episode 636/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0015547327171457903\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 637/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.00333261007029767\n",
      "Loss : -6.509978321486641\n",
      "end while loop iteration :  13\n",
      "Episode 638/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.001399259445431289\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 639/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.002999349063267931\n",
      "Loss : -6.509978321486641\n",
      "end while loop iteration :  13\n",
      "Episode 640/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0012593335008881379\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 641/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 26th iterations\n",
      "Save last state even is out of bound\n",
      "Q table still growths\n",
      "Loss : -57.04342507865867\n",
      "end while loop iteration :  26\n",
      "Episode 642/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.001133400150799324\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 643/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.001020060135719314\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 644/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.01827728379481086\n",
      "Loss : -7.478899909534824\n",
      "end while loop iteration :  14\n",
      "Episode 645/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.0009180541221474048\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 646/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.027803051584358553\n",
      "Loss : -7.726647679116767\n",
      "end while loop iteration :  11\n",
      "Episode 647/1000\n",
      "exploration_prob : 0.100\n",
      "No action possible. Stop episode at 19th iterations\n",
      "Save last state even is out of bound\n",
      "diff Qtable_N - Qtable_N-1  1.310851055178922\n",
      "Loss : -171.78322201769836\n",
      "end while loop iteration :  19\n",
      "Episode 648/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.026980823382515062\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 649/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.024282741044263534\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 650/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.02185446693983717\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 651/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.019669020245853486\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 652/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.017702118221268104\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Episode 653/1000\n",
      "exploration_prob : 0.100\n",
      "stop episode because agent reach goal\n",
      "diff Qtable_N - Qtable_N-1  0.015931906399141327\n",
      "Loss : -6.741719270622925\n",
      "end while loop iteration :  10\n",
      "Look like nothing to learn anymore, stop training\n"
     ]
    }
   ],
   "source": [
    "RL.q_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da876bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RL.plot_convergence()\n",
    "RL.plot_convergence(len(RL.loss_episodes) -50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32fd3427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_y': [175.0],\n",
       " 'speed_y': [0.0],\n",
       " 'weight_rocket': [305],\n",
       " 'booster': [0.0],\n",
       " 'pos_x': [140.0],\n",
       " 'angle': [0.0],\n",
       " 'speed_x': [0.0],\n",
       " 'alpha': [0.0],\n",
       " 'acceleration_x': [0.0],\n",
       " 'm_fuel': [300],\n",
       " 'acceleration_y': [0.0],\n",
       " 'futur_pos_x': [75.0],\n",
       " 'futur_pos_y': [175.0],\n",
       " 'weight_dry_rocket': [5],\n",
       " 'G': [1.62],\n",
       " 'm_fuel_ini': [300.0],\n",
       " 'pos_x_star': [140.0],\n",
       " 'pos_y_star': [0.0],\n",
       " 'pos_x_ini': [75.0],\n",
       " 'pos_y_ini': [175.0],\n",
       " 'upper_boundary': [0.0],\n",
       " 'lower_boundary': [0.0],\n",
       " 'distance_y_reward': [1.0],\n",
       " 'speed_y_reward': [0.0],\n",
       " 'ratio_fuel': [1.0],\n",
       " 'dt': [3],\n",
       " 'time': [0],\n",
       " 'acceleration_limit_y': [10],\n",
       " 'speed_limit_y': [5]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.json[\"initial_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8f740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_y': array([175.        , 160.42      , 140.11245902, 123.07737705,\n",
       "        109.61483745, 100.03518506,  85.18587749,  65.23025414,\n",
       "         49.81117214,  39.2731291 ,  23.97326787,   4.09340665]),\n",
       " 'speed_y': array([ 0.        , -4.86      , -3.81836066, -2.67836066, -1.43666574,\n",
       "        -0.08976919, -4.94976919, -3.49397972, -1.92540829, -0.23995374,\n",
       "        -5.09995374, -3.29328707]),\n",
       " 'weight_rocket': array([305., 305., 300., 295., 290., 285., 285., 280., 275., 270., 270.,\n",
       "        265.])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074dd73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_y</th>\n",
       "      <th>speed_y</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>m_fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.420000</td>\n",
       "      <td>-4.860000</td>\n",
       "      <td>-1.620000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140.112459</td>\n",
       "      <td>-3.818361</td>\n",
       "      <td>0.347213</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123.077377</td>\n",
       "      <td>-2.678361</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.614837</td>\n",
       "      <td>-1.436666</td>\n",
       "      <td>0.413898</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.035185</td>\n",
       "      <td>-0.089769</td>\n",
       "      <td>0.448966</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85.185877</td>\n",
       "      <td>-4.949769</td>\n",
       "      <td>-1.620000</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65.230254</td>\n",
       "      <td>-3.493980</td>\n",
       "      <td>0.485263</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49.811172</td>\n",
       "      <td>-1.925408</td>\n",
       "      <td>0.522857</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.273129</td>\n",
       "      <td>-0.239954</td>\n",
       "      <td>0.561818</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.973268</td>\n",
       "      <td>-5.099954</td>\n",
       "      <td>-1.620000</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.093407</td>\n",
       "      <td>-3.293287</td>\n",
       "      <td>0.602222</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos_y   speed_y  acceleration_y  m_fuel\n",
       "0   175.000000  0.000000        0.000000   300.0\n",
       "1   160.420000 -4.860000       -1.620000   300.0\n",
       "2   140.112459 -3.818361        0.347213   295.0\n",
       "3   123.077377 -2.678361        0.380000   290.0\n",
       "4   109.614837 -1.436666        0.413898   285.0\n",
       "5   100.035185 -0.089769        0.448966   280.0\n",
       "6    85.185877 -4.949769       -1.620000   280.0\n",
       "7    65.230254 -3.493980        0.485263   275.0\n",
       "8    49.811172 -1.925408        0.522857   270.0\n",
       "9    39.273129 -0.239954        0.561818   265.0\n",
       "10   23.973268 -5.099954       -1.620000   265.0\n",
       "11    4.093407 -3.293287        0.602222   260.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(RL.env.all_states([\"pos_y\", \"speed_y\", \"acceleration_y\", \"m_fuel\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85511f9d",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Optimal trajectory</span>\n",
    "\n",
    "Lets see how the rocket evolves after train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fd9c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop: reach goal\n"
     ]
    }
   ],
   "source": [
    "# load policy table\n",
    "policy = RL.q_table.copy().replace(0, np.nan)\n",
    "# load environnment\n",
    "env = Environment(JOSN_file, check_model = False)\n",
    "state = env.state_for_q_table()\n",
    "flag_continue = True\n",
    "while flag_continue:\n",
    "    # control while loop\n",
    "    if not policy.index.isin([str(state)]).any():\n",
    "        flag_continue = False\n",
    "        print(\"stop: no moore state\")\n",
    "        continue\n",
    "    elif env.pos_y[-1] < 0:\n",
    "        print(\"stop: reach goal\")\n",
    "        env.delete_last_states()\n",
    "        flag_continue = False\n",
    "        continue\n",
    "    action = RL.call_choose_action(state, 0)\n",
    "    _, rewards, done, problem, info = env.step(action)\n",
    "    state = env.state_for_q_table()\n",
    "\n",
    "dt = pd.DataFrame(env.all_states())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5731bcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_y</th>\n",
       "      <th>speed_y</th>\n",
       "      <th>weight_rocket</th>\n",
       "      <th>booster</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>angle</th>\n",
       "      <th>speed_x</th>\n",
       "      <th>alpha</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>m_fuel</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_y_ini</th>\n",
       "      <th>upper_boundary</th>\n",
       "      <th>lower_boundary</th>\n",
       "      <th>distance_y_reward</th>\n",
       "      <th>speed_y_reward</th>\n",
       "      <th>ratio_fuel</th>\n",
       "      <th>dt</th>\n",
       "      <th>time</th>\n",
       "      <th>acceleration_limit_y</th>\n",
       "      <th>speed_limit_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.420000</td>\n",
       "      <td>-4.860000</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140.112459</td>\n",
       "      <td>-3.818361</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123.077377</td>\n",
       "      <td>-2.678361</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.614837</td>\n",
       "      <td>-1.436666</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.035185</td>\n",
       "      <td>-0.089769</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85.185877</td>\n",
       "      <td>-4.949769</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65.230254</td>\n",
       "      <td>-3.493980</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49.811172</td>\n",
       "      <td>-1.925408</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.273129</td>\n",
       "      <td>-0.239954</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.973268</td>\n",
       "      <td>-5.099954</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136990</td>\n",
       "      <td>-0.054887</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos_y   speed_y  weight_rocket  booster  pos_x  angle  speed_x  \\\n",
       "0   175.000000  0.000000          305.0      0.0  140.0    0.0      0.0   \n",
       "1   160.420000 -4.860000          305.0      0.0  140.0    0.0      0.0   \n",
       "2   140.112459 -3.818361          300.0      1.0  140.0    0.0      0.0   \n",
       "3   123.077377 -2.678361          295.0      1.0  140.0    0.0      0.0   \n",
       "4   109.614837 -1.436666          290.0      1.0  140.0    0.0      0.0   \n",
       "5   100.035185 -0.089769          285.0      1.0  140.0    0.0      0.0   \n",
       "6    85.185877 -4.949769          285.0      0.0  140.0    0.0      0.0   \n",
       "7    65.230254 -3.493980          280.0      1.0  140.0    0.0      0.0   \n",
       "8    49.811172 -1.925408          275.0      1.0  140.0    0.0      0.0   \n",
       "9    39.273129 -0.239954          270.0      1.0  140.0    0.0      0.0   \n",
       "10   23.973268 -5.099954          270.0      0.0  140.0    0.0      0.0   \n",
       "\n",
       "    alpha  acceleration_x  m_fuel  ...  pos_y_ini  upper_boundary  \\\n",
       "0     0.0             0.0   300.0  ...      175.0             0.0   \n",
       "1     0.0             0.0   300.0  ...      175.0             0.0   \n",
       "2     0.0             0.0   295.0  ...      175.0             0.0   \n",
       "3     0.0             0.0   290.0  ...      175.0             0.0   \n",
       "4     0.0             0.0   285.0  ...      175.0             0.0   \n",
       "5     0.0             0.0   280.0  ...      175.0             0.0   \n",
       "6     0.0             0.0   280.0  ...      175.0             0.0   \n",
       "7     0.0             0.0   275.0  ...      175.0             0.0   \n",
       "8     0.0             0.0   270.0  ...      175.0             0.0   \n",
       "9     0.0             0.0   265.0  ...      175.0             0.0   \n",
       "10    0.0             0.0   265.0  ...      175.0             0.0   \n",
       "\n",
       "    lower_boundary  distance_y_reward  speed_y_reward  ratio_fuel  dt  time  \\\n",
       "0              0.0           1.000000        0.000000    1.000000   3     0   \n",
       "1              0.0           0.916686        0.000000    1.000000   3     3   \n",
       "2              0.0           0.800643        0.000000    0.983333   3     6   \n",
       "3              0.0           0.703299        0.000000    0.966667   3     9   \n",
       "4              0.0           0.626370        0.000000    0.950000   3    12   \n",
       "5              0.0           0.571630        0.000000    0.933333   3    15   \n",
       "6              0.0           0.486776        0.000000    0.933333   3    18   \n",
       "7              0.0           0.372744        0.000000    0.916667   3    21   \n",
       "8              0.0           0.284635        0.000000    0.900000   3    24   \n",
       "9              0.0           0.224418        0.000000    0.883333   3    27   \n",
       "10             0.0           0.136990       -0.054887    0.883333   3    30   \n",
       "\n",
       "    acceleration_limit_y  speed_limit_y  \n",
       "0                     10              5  \n",
       "1                     10              5  \n",
       "2                     10              5  \n",
       "3                     10              5  \n",
       "4                     10              5  \n",
       "5                     10              5  \n",
       "6                     10              5  \n",
       "7                     10              5  \n",
       "8                     10              5  \n",
       "9                     10              5  \n",
       "10                    10              5  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
