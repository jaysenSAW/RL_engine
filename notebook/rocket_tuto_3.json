{
    "states_variables" : ["pos_x", "pos_y", "angle", "speed_x", "speed_y", "weight_rocket"],
    "agent_variables" : ["booster", "alpha"],
    "initial_values" : {
      "pos_x" : [75.0],
      "pos_y" : [175.0],
      "angle" : [0.0],
      "speed_x": [0.0],
      "speed_y": [0.0],
      "weight_rocket" : [305],
      "booster" : [0.0],
      "alpha" : [0.0],
      "acceleration_x": [0.0],
      "acceleration_y": [0.0],
      "m_fuel" : [300],
      "futur_pos_x" : [75.0],
      "futur_pos_y" : [175.0],
      "weight_dry_rocket" : [5],
      "G" : [1.62],
      "m_fuel_ini" : [300.0],
      "pos_x_star": [140.0],
      "pos_y_star": [0.0],
      "pos_x_ini" : [75.0],
      "pos_y_ini" : [175.0],
      "upper_boundary" : [0.0],
      "lower_boundary" : [0.0],
      "dt" : [4]
      },
    "_limit" : ["min", "max", "n_bins"],
    "limit" : {
      "pos_x" : [50.0, 200, 61],
      "pos_y" : [0.0, 250.0, 81],
      "angle" : [-0.8, 0.8, 3],
      "speed_x": [-30.0, 30.0, 13],
      "speed_y": [-30.0, 30.0, 13],
      "weight_rocket" : [0.0, 305, 62],
      "booster" : [0.0, 2.0, 3],
      "alpha" : [-0.8, 0.8, 3],
      "acceleration_x": [-20.0, 20.0, 21],
      "acceleration_y": [-20.0, 20.0, 21],
      "m_fuel" : [0.0, 400, 801]
    },
    "n_action" : {
      "booster": {"0" : 0.0, "1" : 1.0, "2" : 2.0},
      "alpha" : {"0" : -0.8, "1" : 0.0, "2" : 0.8}
    },
    "_action_to_take" : "How action change agent_variables, value is taken from n_action dictionary",
    "action_to_take" : {
      "booster": {"$booster$" : "$action$"},
      "alpha": {"$alpha$" : "$action$"}
    },
    "_equations" : "compute values for each equation. Variable are updated after the loop",
    "equations_variables": {
        "$F$" : "600",
        "_dt" : "2.0",
        "$theta$" : "0.0",
        "$x_0$" : "$pos_x$",
        "$y_0$" : "$pos_y$",
        "$Vx_0$" : "$speed_x$",
        "$Vy_0$" : "$speed_y$",
        "$angle$" : "$angle$ + $alpha$",
        "$m_fuel$" : "$m_fuel$ - $booster$ *5 -np.ceil( np.abs($alpha$) ) *5",
        "$weight_rocket$" : "$weight_dry_rocket$ + $m_fuel$",
        "$acceleration_x$" : "($F$/(5+$weight_rocket$) * np.sin($angle$)) * $booster$",
        "$acceleration_y$" : "($F$/(5+$weight_rocket$) * np.cos($angle$)) * $booster$ - $G$",
        "$speed_x$" : "($F$/(5+$weight_rocket$) * np.sin($angle$)) * $booster$ * $dt$ + $Vx_0$",
        "$speed_y$" : "($F$/(5+$weight_rocket$) * np.cos($angle$)) * $booster$ * $dt$ - $G$ * $dt$ + $Vy_0$",
        "$pos_x$": "(0.5 * $F$/(5+$weight_rocket$) * np.sin($angle$)) * $booster$ * $dt$**2 + $Vx_0$ * $dt$ + $x_0$",
        "$pos_y$": "(0.5 * $F$/(5+$weight_rocket$) * np.cos($angle$)) * $booster$ * $dt$**2 - $G$ * $dt$**2 + $Vy_0$ * $dt$ + $y_0$",
        "$futur_pos_y$" : "$pos_y$ + 3 * $speed_y$",
        "$futur_pos_x$" : "$pos_x$ + 3 * $speed_x$",
        "y_lower_limit" : "0",
        "y_upper_limit" : "200",
        "$upper_boundary$": "-np.exp(0) + np.exp(np.min([ np.min(-$futur_pos_y$ + y_upper_limit), 0]))",
        "$lower_boundary$": "-np.exp(0) + np.exp(np.min([ np.min($futur_pos_y$ -y_lower_limit), 0]))"
    },
    "equations_rewards": {
      "distance_y_reward" : "np.abs( ($pos_y$ - $pos_y_star$)/($pos_y_ini$ - $pos_y_star$) )",
      "distance_x_reward" : "np.abs( ($pos_x$ - $pos_x_star$)/($pos_x_ini$ - $pos_x_star$) )",
      "acceleration_limit_x" : "10",
      "acceleration_limit_y" : "10",
      "acceleration_x_reward" : "np.exp(1) - np.exp( np.max([ np.max( np.abs($acceleration_x$)/acceleration_limit_x), 1 ]) )",
      "acceleration_y_reward" : "np.exp(1) - np.exp( np.max([ np.max( np.abs($acceleration_y$)/acceleration_limit_y), 1 ]) )",
      "speed_limit_x" : "15",
      "speed_limit_y" : "15",
      "speed_x_reward" : "np.exp(1) - np.exp( np.max([ np.max( np.abs($speed_x$)/speed_limit_x ), 1 ]) )",
      "speed_y_reward" : "np.exp(1) - np.exp( np.max([ np.max( np.abs($speed_y$)/speed_limit_y ), 1 ]) )",
      "y_lower_limit" : "0",
      "y_upper_limit" : "200",
      "upper_boundary": "-np.exp(0) + np.exp(np.min([ np.min(-$futur_pos_y$ + y_upper_limit), 0]))",
      "lower_boundary": "-np.exp(0) + np.exp(np.min([ np.min($futur_pos_y$ -y_lower_limit), 0]))",
      "height_boundaries" : "-2 + lower_boundary + upper_boundary",
      "ratio_fuel" : "$m_fuel$/$m_fuel_ini$",
      "_booster" : "3 * distance_y_reward + acceleration_y_reward + speed_y_reward + 2 * height_boundaries + 0.5* ratio_fuel",
      "$booster$" : "2*(-distance_y_reward) + speed_y_reward + 0.5 * ratio_fuel",
      "$alpha$" : "2*(-distance_x_reward)  + speed_x_reward  - 0.2*np.sin($alpha$) + 0.5 * ratio_fuel"
    }, 
    "_stop_episode" : "stop episode when goal is reach.", 
    "_stop_episode_info1" : "If feature has 1 value, its feature's value must be equal", 
    "_stop_episode_info2" : "if feature has 2 values [min_limit, max_limit]. Criterion is bounded feature >= min_limit and feature <= max_limit",
    "stop_episode" : {
      "pos_x" : [135, 145],
      "pos_y" : [0, 5],
      "acceleration_y" : [-2,2],
      "speed_x" : [-10,10],
      "speed_y" : [-10,10]
      },
    "condition_stop_episode_info" : "'all' if all condition must be true, any if one must be true",
    "condition_stop_episode" : "all"
}